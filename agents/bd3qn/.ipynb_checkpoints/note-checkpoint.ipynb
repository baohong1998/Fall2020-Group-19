{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "stunning-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from config import Configuration\n",
    "from noisy_net import NoisyLinear, NoisyFactorizedLinear\n",
    "from utils import state_pre_processing\n",
    "from OneHotEncode import OneHotEncode\n",
    "\n",
    "class BranchingQNetwork(nn.Module):\n",
    "    def __init__(self, observation_space, action_space, hidden_dim, exploration_method=\"Dueling\", architecture=\"Dueling\"):\n",
    "        super().__init__()\n",
    "        self.architecture = architecture\n",
    "        self.model = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(62, hidden_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        ) for i in range(12)])\n",
    "        if self.architecture == \"Dueling\":\n",
    "            self.value_head = nn.ModuleList([nn.Linear(hidden_dim, 1) for i in range(12)])\n",
    "            self.adv_heads = nn.ModuleList([nn.Linear(hidden_dim, 11) for i in range(12)])\n",
    "        else:\n",
    "            self.out = nn.ModuleList([nn.Linear(hidden_dim, 11) for i in range(12)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        processed_x = self.state_processing(x)\n",
    "        layer1 = torch.stack([self.model[i](processed_x[i]) for i, _ in enumerate(processed_x)])\n",
    "        if self.architecture == \"Dueling\":\n",
    "            value = torch.stack([self.value_head[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            advs = torch.stack([self.adv_heads[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            q_val = value + advs - advs.mean()\n",
    "        else:\n",
    "            q_val = torch.stack([self.out[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            \n",
    "        return q_val\n",
    "    \n",
    "    def state_processing(self, obs):\n",
    "        node_info = obs[:45]\n",
    "        groups_info = obs[45:]\n",
    "        partitions = [17 for i in range(12)]\n",
    "        groups = torch.split(groups_info, partitions)\n",
    "        groups_final = [torch.cat((node_info, groups[i])) for i in range(len(groups))]\n",
    "        return groups_final\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "id": "described-financing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1c6396d3e50>"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Configuration(\"configs/config.json\")\n",
    "torch.cuda.init()\n",
    "device = torch.device(\n",
    "    config.device if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "driven-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,\n",
    "          0.,    0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,\n",
    "          0.,  -88.,    0.,    0.,    0., -100.,   16.,    0.,    0.,\n",
    "        100.,   12.,    0.,    1., -100.,   16.,    0.,    0.,  -50.,\n",
    "          7.,    1.,    0.,  -13.,    8.,    0.,    0., -500.,   32.,\n",
    "          3.,    1.,   94.,    1.,    8.,   10.,    2.,   56.,    1.,\n",
    "          7.,    8.,    0.,   93.,    0.,    8.,    6.,    1.,   58.,\n",
    "          0.,    8.,    8.,    2.,    0.,    0.,    0.,    4.,    0.,\n",
    "        100.,    0.,    8.,    7.,    1.,   90.,    0.,    8.,    2.,\n",
    "          2.,  100.,    0.,    8.,    7.,    0.,  100.,    0.,    8.,\n",
    "          2.,    1.,   15.,    0.,    7.,    9.,    2.,   70.,    0.,\n",
    "          8.,    2.,    0.,   91.,    1.,   12.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "essential-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs = OneHotEncode(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "political-alignment",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs = torch.tensor(new_obs).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-integer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "indonesian-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BranchingQNetwork(249,11,128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "amateur-pursuit",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sort() received an invalid combination of arguments - got (reverse=bool, ), but expected one of:\n * (name dim, bool descending)\n * (int dim, bool descending)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-481-f9f269ed74b5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mout_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mout_max_7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mout_max_7\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: sort() received an invalid combination of arguments - got (reverse=bool, ), but expected one of:\n * (name dim, bool descending)\n * (int dim, bool descending)\n"
     ]
    }
   ],
   "source": [
    "out = model(new_obs)\n",
    "out_max = out.max(1)\n",
    "out_max_7 = out_max.values\n",
    "out_max_7.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "streaming-lawyer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  0,  8,  1, 10,  7,  6, 10,  2,  5,  5,  0])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-adelaide",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "through-access",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "associate-favorite",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-movement",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
