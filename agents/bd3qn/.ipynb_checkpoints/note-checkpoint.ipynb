{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stunning-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from config import Configuration\n",
    "from noisy_net import NoisyLinear, NoisyFactorizedLinear\n",
    "from utils import state_pre_processing\n",
    "from OneHotEncode import OneHotEncode\n",
    "\n",
    "class BranchingQNetwork(nn.Module):\n",
    "    def __init__(self, observation_space, action_space, hidden_dim, exploration_method=\"Dueling\", architecture=\"DQN\"):\n",
    "        super().__init__()\n",
    "        self.architecture = architecture\n",
    "        self.model = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(62, hidden_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        ) for i in range(12)])\n",
    "        if self.architecture == \"Dueling\":\n",
    "            self.value_head = nn.ModuleList([nn.Linear(hidden_dim, 1) for i in range(12)])\n",
    "            self.adv_heads = nn.ModuleList([nn.Linear(hidden_dim, 11) for i in range(12)])\n",
    "        else:\n",
    "            self.out = nn.ModuleList([nn.Linear(hidden_dim, 11) for i in range(12)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        processed_x = self.state_processing(x)\n",
    "        #print(processed_x)\n",
    "        layer1 = torch.stack([self.model[i](processed_x[i]) for i, _ in enumerate(processed_x)])\n",
    "        if self.architecture == \"Dueling\":\n",
    "            value = torch.stack([self.value_head[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            advs = torch.stack([self.adv_heads[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            q_val = value + advs - advs.mean()\n",
    "        else:\n",
    "            q_val = torch.stack([self.out[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            \n",
    "        return q_val\n",
    "    \n",
    "    def state_processing(self, obs):\n",
    "        node_info = obs[:45]\n",
    "        groups_info = obs[45:]\n",
    "        partitions = [17 for i in range(12)]\n",
    "        groups = torch.split(groups_info, partitions)\n",
    "        groups_final = [torch.cat((node_info, groups[i])) for i in range(len(groups))]\n",
    "        return groups_final\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wicked-couple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1f9e64d27c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Configuration(\"configs/config.json\")\n",
    "torch.cuda.init()\n",
    "device = torch.device(\n",
    "    config.device if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "combined-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,\n",
    "          0.,    0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,\n",
    "          0.,  -88.,    0.,    0.,    0., -100.,   16.,    0.,    0.,\n",
    "        100.,   12.,    0.,    1., -100.,   16.,    0.,    0.,  -50.,\n",
    "          7.,    1.,    0.,  -13.,    8.,    0.,    0., -500.,   32.,\n",
    "          3.,    1.,   94.,    1.,    8.,   10.,    2.,   56.,    1.,\n",
    "          7.,    8.,    0.,   93.,    0.,    8.,    6.,    1.,   58.,\n",
    "          0.,    8.,    8.,    2.,    0.,    0.,    0.,    4.,    0.,\n",
    "        100.,    0.,    8.,    7.,    1.,   90.,    0.,    8.,    2.,\n",
    "          2.,  100.,    0.,    8.,    7.,    0.,  100.,    0.,    8.,\n",
    "          2.,    1.,   15.,    0.,    7.,    9.,    2.,   70.,    0.,\n",
    "          8.,    2.,    0.,   91.,    1.,   12.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "korean-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs = OneHotEncode(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eastern-denmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
       "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
       "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
       "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
       "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    1.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,   94.,\n",
       "           1.,    8.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    1.,    0.,    0.,    1.,   56.,    1.,    7.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "           1.,    0.,    0.,   93.,    0.,    8.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
       "          58.,    0.,    8.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    1.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    1.,    0.,    0.,  100.,    0.,    8.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    1.,\n",
       "           0.,   90.,    0.,    8.,    0.,    0.,    1.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,  100.,    0.,\n",
       "           8.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
       "           0.,    0.,    1.,    0.,    0.,  100.,    0.,    8.,    0.,    0.,\n",
       "           1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           1.,    0.,   15.,    0.,    7.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    1.,   70.,\n",
       "           0.,    8.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    1.,    0.,    0.,   91.,    1.,   12.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs = torch.tensor(new_obs).float().to(device)\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-moment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adverse-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BranchingQNetwork(\n",
       "  (model): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (out): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (3): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (4): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (5): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (6): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (7): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (8): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (9): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (10): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (11): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BranchingQNetwork(249,11,128)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "above-august",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.9020, -2.6777, -0.8610, -1.3483, -0.7833, -8.3360, -4.6109,  2.2436,\n",
      "          1.3109,  5.1803, -0.7092],\n",
      "        [ 1.4493,  3.9153,  6.1884, -1.7723,  1.5198,  6.0655,  4.6400,  2.4675,\n",
      "          2.3097,  3.5910, -6.4122],\n",
      "        [ 0.5694,  0.8096, -0.0370,  1.8791,  3.9980, -4.0703, -1.9475, -2.6174,\n",
      "          0.2954,  0.2050,  0.1179],\n",
      "        [ 7.0691,  1.5045,  1.5875,  0.6541,  5.8861,  0.5254,  3.2723,  2.5873,\n",
      "          4.3878,  5.8561,  1.8414],\n",
      "        [-2.5419, -4.6274, -5.4703,  3.0516, -4.0267,  1.8106, -5.2737, -1.8081,\n",
      "          1.4377,  0.1265, -4.3325],\n",
      "        [-0.6096,  4.3651, -0.2477,  2.2767,  2.0451, -3.4724, -2.3883,  1.2757,\n",
      "          5.6066, -2.4234, -2.2584],\n",
      "        [ 2.8746,  5.3597,  4.5418,  5.9028, -3.7635, -0.2702, -1.5322,  0.7782,\n",
      "          2.7711,  2.9967,  3.3838],\n",
      "        [-5.4440, -2.2268, -3.6689, -0.3324, -3.8233,  2.7718, -2.4710,  1.5707,\n",
      "          2.9060,  0.8373, -3.5100],\n",
      "        [ 5.0995, -3.0545, -0.7478,  1.5264,  2.2042,  2.7104,  3.8909,  4.3617,\n",
      "         -2.5294, -2.1418, -3.1611],\n",
      "        [-4.9575,  0.0854,  0.2298,  9.7555,  4.0560, -2.4555, -1.4916, -2.7079,\n",
      "         -5.5517, -6.1841,  0.7258],\n",
      "        [-3.4224,  4.2339,  8.0474, -2.5513,  0.5833, -1.9557,  1.0226,  8.6733,\n",
      "          0.2784, -0.5715, -1.5888],\n",
      "        [-1.5698, -3.5892, -0.3476, -3.2141, -4.5706,  0.4733,  6.3694, -0.4448,\n",
      "         -5.5143,  0.7036, -6.8636]], device='cuda:0', grad_fn=<StackBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([5.1803, 6.1884, 3.9980, 7.0691, 3.0516, 5.6066, 5.9028, 2.9060, 5.0995,\n",
      "        9.7555, 8.6733, 6.3694], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([9, 2, 4, 0, 3, 8, 3, 8, 0, 3, 7, 6], device='cuda:0'))\n",
      "torch.return_types.sort(\n",
      "values=tensor([9.7555, 8.6733, 7.0691, 6.3694, 6.1884, 5.9028, 5.6066, 5.1803, 5.0995,\n",
      "        3.9980, 3.0516, 2.9060], device='cuda:0', grad_fn=<SortBackward>),\n",
      "indices=tensor([ 9, 10,  3, 11,  1,  6,  5,  0,  8,  2,  4,  7], device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 9,  4],\n",
       "       [10,  8],\n",
       "       [ 3,  1],\n",
       "       [11,  7],\n",
       "       [ 1,  3],\n",
       "       [ 6,  4],\n",
       "       [ 5,  9]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(new_obs)\n",
    "print(out)\n",
    "out_max = out.max(1)\n",
    "print(out_max)\n",
    "out_max_sorted = out_max.values.sort(descending=True)\n",
    "print(out_max_sorted)\n",
    "chosen_group = out_max_sorted.indices[:7]\n",
    "chosen_location = torch.stack([out_max.indices[i] for i in chosen_group]) + 1\n",
    "action = torch.stack([chosen_group, chosen_location], dim = 1)\n",
    "action.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "consolidated-comedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9, 2, 4, 0, 3, 8, 3, 8, 0, 3, 7, 6], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "involved-portuguese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[5.1803],\n",
       "        [6.1884],\n",
       "        [3.9980],\n",
       "        [7.0691],\n",
       "        [3.0516],\n",
       "        [5.6066],\n",
       "        [5.9028],\n",
       "        [2.9060],\n",
       "        [5.0995],\n",
       "        [9.7555],\n",
       "        [8.6733],\n",
       "        [6.3694]], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([[9],\n",
       "        [2],\n",
       "        [4],\n",
       "        [0],\n",
       "        [3],\n",
       "        [8],\n",
       "        [3],\n",
       "        [8],\n",
       "        [0],\n",
       "        [3],\n",
       "        [7],\n",
       "        [6]], device='cuda:0'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = out.max(1, keepdim=True)\n",
    "q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "greatest-heating",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 2] at entry 0 and [1] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f47ec939c789>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 2] at entry 0 and [1] at entry 1"
     ]
    }
   ],
   "source": [
    "g = torch.tensor([5])\n",
    "for i in range(5):\n",
    "    g = torch.stack((g,torch.tensor([5])),1)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "heard-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(16)\n",
    "a = a.reshape(16,1,1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "focal-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2276]],\n",
       "\n",
       "        [[0.4942]],\n",
       "\n",
       "        [[0.9266]],\n",
       "\n",
       "        [[0.0940]],\n",
       "\n",
       "        [[0.2169]],\n",
       "\n",
       "        [[0.5311]],\n",
       "\n",
       "        [[0.6452]],\n",
       "\n",
       "        [[0.2567]],\n",
       "\n",
       "        [[0.4689]],\n",
       "\n",
       "        [[0.6318]],\n",
       "\n",
       "        [[0.2457]],\n",
       "\n",
       "        [[0.1645]],\n",
       "\n",
       "        [[0.1003]],\n",
       "\n",
       "        [[0.1968]],\n",
       "\n",
       "        [[0.0496]],\n",
       "\n",
       "        [[0.2462]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dirty-banking",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adverse-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1409, 0.9135, 0.1956, 0.5351, 0.8767, 0.9059, 0.9668, 0.5254,\n",
       "          0.8901, 0.8311, 0.1479]],\n",
       "\n",
       "        [[0.5783, 0.3645, 0.5010, 0.9720, 0.0453, 0.0646, 0.7823, 0.3192,\n",
       "          0.6586, 0.6066, 0.0733]],\n",
       "\n",
       "        [[0.0016, 0.4700, 0.8568, 0.4734, 0.2790, 0.8545, 0.7776, 0.6796,\n",
       "          0.0137, 0.6813, 0.0604]],\n",
       "\n",
       "        [[0.1228, 0.6575, 0.6607, 0.7180, 0.0462, 0.6034, 0.6933, 0.0272,\n",
       "          0.0079, 0.1705, 0.3592]],\n",
       "\n",
       "        [[0.1513, 0.1571, 0.9631, 0.4855, 0.3229, 0.9497, 0.4082, 0.8003,\n",
       "          0.3726, 0.6891, 0.5113]],\n",
       "\n",
       "        [[0.3264, 0.3929, 0.2047, 0.5997, 0.6581, 0.2868, 0.6920, 0.2254,\n",
       "          0.6807, 0.5510, 0.1217]],\n",
       "\n",
       "        [[0.1221, 0.7400, 0.6622, 0.1505, 0.9949, 0.0253, 0.0817, 0.2848,\n",
       "          0.8047, 0.3968, 0.5452]],\n",
       "\n",
       "        [[0.8734, 0.0869, 0.5105, 0.0908, 0.6852, 0.2858, 0.8747, 0.4453,\n",
       "          0.8012, 0.3103, 0.6997]],\n",
       "\n",
       "        [[0.6785, 0.7149, 0.3171, 0.4268, 0.2233, 0.7391, 0.7505, 0.2933,\n",
       "          0.1239, 0.4385, 0.5474]],\n",
       "\n",
       "        [[0.6519, 0.9210, 0.2613, 0.5981, 0.3936, 0.3549, 0.3579, 0.9382,\n",
       "          0.6226, 0.9866, 0.2787]],\n",
       "\n",
       "        [[0.6205, 0.8403, 0.0054, 0.6436, 0.2486, 0.0702, 0.0810, 0.0268,\n",
       "          0.3892, 0.7295, 0.7932]],\n",
       "\n",
       "        [[0.3198, 0.4475, 0.8704, 0.2895, 0.8391, 0.4721, 0.2132, 0.5169,\n",
       "          0.8603, 0.8540, 0.1987]],\n",
       "\n",
       "        [[0.5805, 0.2197, 0.0508, 0.4730, 0.2625, 0.7141, 0.9365, 0.3223,\n",
       "          0.1203, 0.1260, 0.0249]],\n",
       "\n",
       "        [[0.0206, 0.8795, 0.8750, 0.2308, 0.6854, 0.4934, 0.4572, 0.3469,\n",
       "          0.4196, 0.1775, 0.8207]],\n",
       "\n",
       "        [[0.7824, 0.2422, 0.4120, 0.2775, 0.9120, 0.0162, 0.8918, 0.0247,\n",
       "          0.6280, 0.1369, 0.8042]],\n",
       "\n",
       "        [[0.3623, 0.6814, 0.0546, 0.4295, 0.6346, 0.3130, 0.8900, 0.6984,\n",
       "          0.6219, 0.5646, 0.6857]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(16,1,11)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "prepared-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3685, 1.1410, 0.4232, 0.7627, 1.1043, 1.1335, 1.1944, 0.7529,\n",
       "          1.1176, 1.0586, 0.3754]],\n",
       "\n",
       "        [[1.0725, 0.8587, 0.9952, 1.4662, 0.5395, 0.5588, 1.2765, 0.8133,\n",
       "          1.1527, 1.1007, 0.5675]],\n",
       "\n",
       "        [[0.9282, 1.3966, 1.7835, 1.4000, 1.2056, 1.7812, 1.7042, 1.6062,\n",
       "          0.9403, 1.6079, 0.9871]],\n",
       "\n",
       "        [[0.2168, 0.7515, 0.7546, 0.8120, 0.1401, 0.6974, 0.7873, 0.1212,\n",
       "          0.1019, 0.2645, 0.4532]],\n",
       "\n",
       "        [[0.3683, 0.3740, 1.1800, 0.7024, 0.5399, 1.1666, 0.6251, 1.0172,\n",
       "          0.5895, 0.9061, 0.7282]],\n",
       "\n",
       "        [[0.8575, 0.9240, 0.7359, 1.1309, 1.1892, 0.8179, 1.2232, 0.7565,\n",
       "          1.2118, 1.0821, 0.6529]],\n",
       "\n",
       "        [[0.7672, 1.3851, 1.3073, 0.7957, 1.6401, 0.6705, 0.7269, 0.9299,\n",
       "          1.4499, 1.0419, 1.1904]],\n",
       "\n",
       "        [[1.1301, 0.3437, 0.7672, 0.3475, 0.9420, 0.5425, 1.1314, 0.7020,\n",
       "          1.0579, 0.5670, 0.9564]],\n",
       "\n",
       "        [[1.1473, 1.1837, 0.7860, 0.8956, 0.6922, 1.2079, 1.2194, 0.7622,\n",
       "          0.5927, 0.9074, 1.0163]],\n",
       "\n",
       "        [[1.2837, 1.5527, 0.8930, 1.2299, 1.0254, 0.9867, 0.9897, 1.5700,\n",
       "          1.2544, 1.6184, 0.9104]],\n",
       "\n",
       "        [[0.8662, 1.0860, 0.2511, 0.8894, 0.4943, 0.3160, 0.3267, 0.2725,\n",
       "          0.6350, 0.9752, 1.0389]],\n",
       "\n",
       "        [[0.4843, 0.6120, 1.0349, 0.4540, 1.0036, 0.6366, 0.3777, 0.6814,\n",
       "          1.0248, 1.0185, 0.3632]],\n",
       "\n",
       "        [[0.6808, 0.3199, 0.1511, 0.5732, 0.3627, 0.8143, 1.0368, 0.4226,\n",
       "          0.2206, 0.2262, 0.1252]],\n",
       "\n",
       "        [[0.2174, 1.0763, 1.0718, 0.4276, 0.8822, 0.6902, 0.6540, 0.5437,\n",
       "          0.6164, 0.3742, 1.0175]],\n",
       "\n",
       "        [[0.8319, 0.2917, 0.4616, 0.3270, 0.9615, 0.0658, 0.9413, 0.0743,\n",
       "          0.6776, 0.1864, 0.8538]],\n",
       "\n",
       "        [[0.6085, 0.9276, 0.3008, 0.6757, 0.8808, 0.5591, 1.1362, 0.9446,\n",
       "          0.8681, 0.8108, 0.9319]]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "lucky-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "considerable-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[9.0634e-01, 3.6819e-01, 1.6183e-01,  ..., 7.5799e-01,\n",
       "          8.4424e-01, 4.2412e-01],\n",
       "         [6.0448e-01, 5.4335e-01, 7.4203e-01,  ..., 7.0699e-01,\n",
       "          2.7163e-01, 5.6318e-01],\n",
       "         [4.8601e-01, 8.6404e-01, 8.9060e-01,  ..., 1.6247e-01,\n",
       "          4.6965e-01, 7.0303e-01],\n",
       "         ...,\n",
       "         [4.9919e-02, 9.8319e-01, 8.8738e-01,  ..., 4.9448e-01,\n",
       "          7.5336e-01, 4.9672e-01],\n",
       "         [1.3585e-01, 7.6376e-01, 7.1237e-01,  ..., 5.7086e-01,\n",
       "          1.8680e-01, 8.0998e-01],\n",
       "         [7.3872e-01, 9.8578e-01, 8.4271e-01,  ..., 9.4244e-01,\n",
       "          4.2971e-01, 3.4733e-01]],\n",
       "\n",
       "        [[9.4890e-01, 8.7925e-01, 7.4226e-01,  ..., 2.3118e-01,\n",
       "          6.8572e-01, 8.9810e-01],\n",
       "         [1.3254e-01, 9.7431e-01, 3.0210e-01,  ..., 6.2608e-01,\n",
       "          9.6138e-01, 4.9180e-01],\n",
       "         [7.0091e-01, 2.5027e-01, 2.3231e-01,  ..., 5.8622e-01,\n",
       "          8.2803e-01, 1.6477e-01],\n",
       "         ...,\n",
       "         [6.6064e-01, 5.3339e-01, 7.8149e-01,  ..., 9.4813e-01,\n",
       "          2.1327e-01, 4.2384e-01],\n",
       "         [8.0514e-01, 3.3862e-01, 9.0973e-01,  ..., 6.3788e-01,\n",
       "          5.1721e-01, 3.0019e-01],\n",
       "         [3.9204e-01, 3.5452e-01, 3.0403e-01,  ..., 8.4095e-01,\n",
       "          2.3030e-01, 5.7152e-01]],\n",
       "\n",
       "        [[3.3001e-01, 1.8540e-01, 6.6195e-02,  ..., 8.6750e-01,\n",
       "          9.9760e-01, 4.4830e-01],\n",
       "         [7.6024e-01, 8.0788e-04, 6.7180e-01,  ..., 9.1264e-01,\n",
       "          3.2791e-01, 4.6526e-01],\n",
       "         [6.9231e-01, 6.4233e-01, 9.6493e-01,  ..., 2.1866e-01,\n",
       "          4.5531e-01, 2.0170e-01],\n",
       "         ...,\n",
       "         [7.6113e-01, 2.6104e-01, 5.7107e-01,  ..., 2.5437e-01,\n",
       "          7.0990e-01, 3.3189e-01],\n",
       "         [8.6380e-01, 7.3401e-01, 3.8624e-02,  ..., 4.1655e-01,\n",
       "          3.2913e-01, 9.5313e-01],\n",
       "         [7.9224e-01, 9.2096e-01, 7.1928e-01,  ..., 4.4402e-01,\n",
       "          4.3195e-01, 7.8862e-02]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[3.3131e-01, 4.2472e-01, 2.4203e-01,  ..., 9.8301e-01,\n",
       "          5.1332e-01, 8.6530e-01],\n",
       "         [2.4764e-01, 7.1404e-01, 3.0165e-01,  ..., 2.6741e-01,\n",
       "          2.9212e-01, 7.8893e-01],\n",
       "         [4.2238e-02, 9.5805e-01, 8.8981e-01,  ..., 8.6785e-01,\n",
       "          5.0283e-01, 7.6542e-01],\n",
       "         ...,\n",
       "         [1.0160e-01, 8.9315e-01, 2.2838e-01,  ..., 5.1255e-01,\n",
       "          9.7898e-01, 6.8019e-01],\n",
       "         [8.8077e-01, 1.7921e-01, 1.4419e-01,  ..., 4.2349e-01,\n",
       "          9.2344e-01, 1.1849e-02],\n",
       "         [9.9865e-01, 1.1765e-01, 8.4913e-01,  ..., 2.0245e-01,\n",
       "          5.6011e-01, 6.2592e-01]],\n",
       "\n",
       "        [[5.5331e-01, 4.0892e-01, 2.4410e-02,  ..., 2.0121e-01,\n",
       "          9.5278e-02, 8.1953e-01],\n",
       "         [4.1150e-01, 5.5962e-01, 6.9857e-01,  ..., 1.7577e-01,\n",
       "          3.7485e-01, 8.3632e-01],\n",
       "         [4.9845e-01, 8.2325e-01, 7.9107e-01,  ..., 9.0816e-01,\n",
       "          2.4628e-01, 5.0777e-01],\n",
       "         ...,\n",
       "         [5.2574e-01, 5.6603e-01, 4.3082e-01,  ..., 3.0442e-01,\n",
       "          3.7020e-01, 4.6010e-02],\n",
       "         [7.2421e-01, 8.6864e-01, 1.7900e-01,  ..., 4.0296e-01,\n",
       "          2.1887e-01, 2.0299e-01],\n",
       "         [8.9667e-01, 9.1886e-01, 7.2061e-01,  ..., 1.9916e-01,\n",
       "          2.9307e-01, 7.4453e-01]],\n",
       "\n",
       "        [[5.9648e-01, 3.7806e-01, 1.5126e-01,  ..., 7.7319e-01,\n",
       "          4.1565e-01, 9.0002e-01],\n",
       "         [5.1682e-02, 6.2997e-01, 3.9256e-01,  ..., 4.5224e-01,\n",
       "          3.0946e-02, 3.0905e-01],\n",
       "         [9.5705e-01, 6.4299e-01, 5.6811e-02,  ..., 9.8950e-01,\n",
       "          3.9613e-01, 6.1109e-01],\n",
       "         ...,\n",
       "         [4.9459e-01, 4.2924e-01, 2.9175e-01,  ..., 2.6920e-01,\n",
       "          3.9210e-01, 6.0514e-01],\n",
       "         [4.5093e-01, 6.0261e-01, 1.3301e-02,  ..., 7.9907e-01,\n",
       "          5.6095e-02, 6.7414e-01],\n",
       "         [6.3105e-01, 8.1555e-01, 6.2285e-01,  ..., 7.6857e-01,\n",
       "          2.6901e-01, 4.2757e-01]]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = torch.rand(16,12,62)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "operating-presentation",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-18-d425bf9ff9b9>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-18-d425bf9ff9b9>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    # idx\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "idx = [[n for x in range(12)]\n",
    "# for n in range(1):\n",
    "#     idx.append([[x for x in range(62)] for k in range(12)])\n",
    "# idx = torch.LongTensor(idx)\n",
    "# idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aware-lightning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0634e-01, 3.6819e-01, 1.6183e-01, 6.1783e-02, 7.5748e-01, 5.3435e-01,\n",
       "         9.0489e-01, 4.2322e-01, 2.1452e-02, 3.4708e-01, 4.6065e-01, 9.6804e-04,\n",
       "         4.4811e-01, 2.5523e-01, 5.1219e-01, 6.0646e-01, 8.9461e-01, 3.6300e-01,\n",
       "         5.1894e-01, 1.5556e-01, 3.5789e-01, 4.6786e-01, 9.4625e-02, 4.5425e-01,\n",
       "         3.3776e-01, 9.0104e-01, 4.4940e-01, 4.1516e-01, 3.5882e-01, 2.1876e-01,\n",
       "         8.6680e-01, 8.4617e-01, 2.0557e-01, 5.8066e-01, 5.9418e-01, 3.7971e-02,\n",
       "         3.7494e-01, 6.6955e-01, 1.2190e-01, 7.4618e-01, 4.1675e-01, 6.7977e-01,\n",
       "         3.6369e-01, 7.9110e-02, 2.5585e-01, 6.1226e-01, 5.1925e-01, 3.1409e-02,\n",
       "         5.4210e-02, 8.5982e-01, 8.9860e-01, 3.9133e-01, 8.1209e-01, 2.8309e-01,\n",
       "         6.5712e-01, 2.8152e-01, 4.7462e-01, 8.4409e-01, 4.1831e-01, 7.5799e-01,\n",
       "         8.4424e-01, 4.2412e-01],\n",
       "        [9.4890e-01, 8.7925e-01, 7.4226e-01, 5.0210e-02, 7.8545e-01, 4.0067e-01,\n",
       "         6.7424e-01, 4.2624e-01, 9.8032e-02, 2.4611e-01, 2.4971e-01, 3.1845e-01,\n",
       "         6.4704e-01, 5.2195e-01, 4.4802e-01, 2.2361e-01, 4.0360e-01, 9.0358e-01,\n",
       "         2.8330e-01, 1.6936e-01, 1.6242e-02, 9.4372e-02, 3.5141e-01, 4.3037e-01,\n",
       "         9.3244e-01, 9.9798e-01, 4.4447e-01, 8.9469e-02, 2.9621e-01, 2.2342e-01,\n",
       "         6.6248e-01, 1.3226e-01, 2.6022e-01, 6.1255e-01, 8.5765e-01, 8.5624e-01,\n",
       "         2.4433e-01, 3.2714e-01, 2.7293e-01, 4.0623e-01, 4.2318e-01, 2.0311e-01,\n",
       "         3.2028e-01, 5.0442e-01, 8.9611e-01, 9.1477e-01, 3.0221e-01, 4.1221e-01,\n",
       "         6.6263e-01, 9.0426e-01, 5.6716e-01, 4.0777e-01, 9.1699e-01, 5.5502e-01,\n",
       "         9.4214e-02, 9.4609e-01, 6.7398e-01, 3.4634e-01, 9.9243e-01, 2.3118e-01,\n",
       "         6.8572e-01, 8.9810e-01]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([st[0][0], st[1][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "civilian-caution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16, 62])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st.transpose(0,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "enormous-campbell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9.0634e-01, 3.6819e-01, 1.6183e-01, 6.1783e-02, 7.5748e-01, 5.3435e-01,\n",
       "         9.0489e-01, 4.2322e-01, 2.1452e-02, 3.4708e-01, 4.6065e-01, 9.6804e-04,\n",
       "         4.4811e-01, 2.5523e-01, 5.1219e-01, 6.0646e-01, 8.9461e-01, 3.6300e-01,\n",
       "         5.1894e-01, 1.5556e-01, 3.5789e-01, 4.6786e-01, 9.4625e-02, 4.5425e-01,\n",
       "         3.3776e-01, 9.0104e-01, 4.4940e-01, 4.1516e-01, 3.5882e-01, 2.1876e-01,\n",
       "         8.6680e-01, 8.4617e-01, 2.0557e-01, 5.8066e-01, 5.9418e-01, 3.7971e-02,\n",
       "         3.7494e-01, 6.6955e-01, 1.2190e-01, 7.4618e-01, 4.1675e-01, 6.7977e-01,\n",
       "         3.6369e-01, 7.9110e-02, 2.5585e-01, 6.1226e-01, 5.1925e-01, 3.1409e-02,\n",
       "         5.4210e-02, 8.5982e-01, 8.9860e-01, 3.9133e-01, 8.1209e-01, 2.8309e-01,\n",
       "         6.5712e-01, 2.8152e-01, 4.7462e-01, 8.4409e-01, 4.1831e-01, 7.5799e-01,\n",
       "         8.4424e-01, 4.2412e-01],\n",
       "        [6.0448e-01, 5.4335e-01, 7.4203e-01, 5.7446e-01, 6.5888e-01, 6.4708e-01,\n",
       "         5.6514e-01, 8.0336e-01, 6.5059e-01, 3.9673e-01, 6.3339e-01, 5.4990e-02,\n",
       "         6.3150e-01, 2.7287e-01, 8.6956e-01, 5.2031e-01, 8.6557e-01, 4.4474e-01,\n",
       "         8.4295e-01, 7.4751e-01, 9.5166e-01, 5.8802e-01, 9.9733e-01, 1.7817e-01,\n",
       "         9.7060e-01, 1.8676e-01, 8.6662e-01, 9.9264e-02, 2.7845e-01, 9.9680e-01,\n",
       "         3.8812e-01, 7.5823e-01, 5.0123e-01, 5.1764e-01, 3.0327e-01, 3.5337e-01,\n",
       "         1.1232e-01, 5.1965e-01, 8.8834e-01, 7.9688e-01, 2.7236e-01, 3.3576e-01,\n",
       "         1.0246e-01, 6.6343e-01, 7.5517e-01, 8.5767e-01, 5.8151e-01, 8.2952e-01,\n",
       "         9.8231e-01, 5.2745e-01, 5.0421e-01, 7.8481e-01, 3.5935e-01, 7.9235e-01,\n",
       "         8.2583e-01, 2.1649e-01, 5.3918e-01, 5.7080e-01, 7.5506e-01, 7.0699e-01,\n",
       "         2.7163e-01, 5.6318e-01],\n",
       "        [4.8601e-01, 8.6404e-01, 8.9060e-01, 5.4693e-01, 1.1551e-01, 3.4818e-01,\n",
       "         6.5019e-01, 4.4610e-01, 2.4570e-01, 9.2966e-01, 4.0725e-01, 2.0319e-01,\n",
       "         6.9658e-01, 4.6152e-01, 4.4723e-01, 9.7056e-01, 5.0531e-01, 1.7215e-01,\n",
       "         8.2965e-01, 4.8900e-01, 6.4495e-01, 5.6370e-01, 6.1197e-01, 1.5154e-01,\n",
       "         5.8608e-01, 2.4712e-01, 7.7594e-01, 8.3180e-02, 5.0276e-02, 5.9525e-01,\n",
       "         9.2979e-01, 1.4193e-01, 2.0700e-01, 5.4102e-01, 4.4121e-01, 6.8891e-01,\n",
       "         8.7287e-01, 6.3992e-01, 7.7911e-01, 8.1277e-01, 9.7978e-01, 3.7884e-01,\n",
       "         7.4140e-01, 2.4476e-01, 9.6746e-02, 5.2693e-01, 3.4021e-01, 3.5753e-01,\n",
       "         7.4475e-01, 6.8721e-01, 7.5082e-01, 5.7334e-01, 6.8281e-01, 5.7170e-01,\n",
       "         3.9031e-01, 9.4225e-02, 8.8479e-01, 2.2880e-01, 4.0012e-01, 1.6247e-01,\n",
       "         4.6965e-01, 7.0303e-01],\n",
       "        [1.6850e-01, 3.9012e-01, 9.3520e-01, 4.0257e-01, 9.4579e-01, 9.3300e-01,\n",
       "         5.3848e-01, 5.0100e-01, 1.5294e-01, 9.7742e-01, 1.9007e-01, 8.9519e-01,\n",
       "         9.5890e-01, 4.9165e-01, 6.0628e-01, 4.5553e-01, 5.1642e-01, 6.0135e-01,\n",
       "         5.6671e-02, 3.5306e-01, 6.7069e-01, 8.9320e-01, 5.8595e-01, 8.9252e-01,\n",
       "         2.2177e-01, 1.0345e-01, 3.8306e-01, 8.6226e-02, 4.4044e-01, 2.1280e-01,\n",
       "         9.3583e-01, 1.6834e-01, 2.4663e-01, 1.8799e-01, 2.8071e-02, 9.9369e-01,\n",
       "         9.8836e-01, 3.5244e-02, 1.9491e-01, 3.2011e-02, 9.1429e-01, 7.1515e-02,\n",
       "         1.9475e-01, 4.5841e-01, 9.2142e-01, 6.1234e-01, 7.3683e-01, 3.7620e-01,\n",
       "         9.2402e-02, 2.6414e-01, 1.8253e-01, 7.2892e-01, 6.8698e-01, 5.6100e-02,\n",
       "         6.0520e-02, 1.9649e-01, 9.4356e-01, 4.3682e-01, 8.0489e-02, 5.6608e-01,\n",
       "         4.9666e-01, 4.8563e-01],\n",
       "        [9.3854e-02, 9.7711e-01, 3.4280e-01, 6.4053e-01, 1.2909e-01, 4.9299e-01,\n",
       "         7.8173e-02, 3.3600e-01, 6.7195e-01, 5.1604e-01, 9.0688e-01, 6.0161e-01,\n",
       "         5.0531e-01, 6.8099e-01, 2.6734e-02, 2.9832e-01, 5.8682e-01, 4.1977e-01,\n",
       "         9.0729e-01, 7.4532e-02, 6.4104e-02, 6.0915e-01, 3.5146e-01, 4.6840e-01,\n",
       "         9.0796e-01, 2.2272e-02, 1.5311e-02, 3.0318e-01, 4.5308e-01, 7.9349e-02,\n",
       "         2.5532e-01, 6.2730e-01, 4.7004e-01, 6.7097e-01, 3.0887e-01, 9.2471e-01,\n",
       "         6.6591e-01, 6.4870e-01, 4.6435e-01, 9.0894e-01, 3.3342e-01, 9.2256e-02,\n",
       "         4.0869e-02, 6.2032e-01, 2.4239e-01, 8.9424e-01, 8.9734e-01, 5.6186e-01,\n",
       "         2.7159e-01, 4.6876e-01, 8.4223e-01, 9.9021e-01, 7.6833e-01, 6.2891e-01,\n",
       "         1.1864e-01, 4.8212e-01, 5.3378e-01, 4.8727e-01, 4.1761e-01, 3.9639e-01,\n",
       "         7.3594e-02, 9.4534e-01],\n",
       "        [5.3655e-01, 8.7186e-03, 6.2606e-01, 4.3848e-01, 3.8079e-01, 3.4522e-01,\n",
       "         7.5389e-01, 5.2466e-01, 6.8374e-01, 1.9690e-01, 4.2382e-01, 9.7877e-01,\n",
       "         8.3129e-01, 2.6943e-01, 2.1506e-01, 7.3045e-01, 9.8571e-01, 8.7011e-01,\n",
       "         8.6794e-01, 7.9168e-01, 1.0842e-01, 2.6726e-01, 9.7362e-01, 9.2160e-01,\n",
       "         1.7659e-01, 8.7472e-01, 8.3352e-01, 5.2999e-01, 9.1138e-01, 1.3737e-02,\n",
       "         3.9942e-01, 8.4306e-01, 7.0664e-01, 3.8224e-02, 8.8844e-01, 8.7568e-01,\n",
       "         1.8478e-01, 5.2456e-02, 3.3759e-01, 2.2641e-01, 6.6785e-01, 5.9282e-01,\n",
       "         5.7028e-01, 8.6766e-01, 2.4998e-01, 2.4697e-01, 8.3781e-01, 1.7748e-02,\n",
       "         1.2225e-01, 8.5921e-01, 9.0344e-02, 5.9570e-01, 2.9182e-01, 7.3984e-01,\n",
       "         5.2045e-02, 5.9116e-01, 1.7494e-02, 7.7561e-01, 7.8197e-01, 7.5230e-01,\n",
       "         6.3247e-01, 9.0465e-01],\n",
       "        [9.5260e-01, 4.9490e-01, 2.9172e-01, 5.4945e-01, 6.4015e-01, 8.4761e-01,\n",
       "         7.2644e-01, 8.7713e-01, 2.4717e-01, 2.3583e-01, 4.3082e-01, 4.0256e-01,\n",
       "         6.9152e-01, 3.4115e-01, 4.0037e-01, 7.0529e-01, 2.0889e-01, 3.6629e-01,\n",
       "         4.9375e-01, 6.4861e-01, 9.6011e-01, 1.4144e-01, 6.3636e-01, 6.1995e-01,\n",
       "         2.5963e-01, 9.9639e-02, 3.2228e-01, 8.1931e-02, 4.5095e-01, 9.2483e-02,\n",
       "         7.9395e-01, 2.4080e-01, 6.4832e-01, 8.0058e-02, 1.3458e-01, 1.9340e-01,\n",
       "         1.3034e-01, 7.5064e-01, 7.9403e-01, 9.6419e-01, 8.2285e-01, 2.4760e-01,\n",
       "         5.4909e-01, 3.8029e-01, 3.6927e-02, 3.0244e-02, 3.7403e-01, 7.0568e-01,\n",
       "         1.2109e-01, 4.7915e-02, 5.9781e-01, 8.5988e-01, 6.7850e-01, 6.2529e-01,\n",
       "         1.0433e-01, 8.5499e-01, 2.9593e-01, 5.0866e-01, 2.3528e-01, 3.1635e-01,\n",
       "         8.4889e-01, 8.7009e-02],\n",
       "        [2.5198e-01, 8.2662e-01, 7.7843e-01, 2.3299e-01, 3.5718e-01, 1.9843e-01,\n",
       "         6.8342e-01, 8.0352e-01, 8.8694e-01, 9.8546e-01, 9.2678e-02, 7.5687e-01,\n",
       "         7.7586e-01, 2.9436e-01, 1.6383e-02, 1.0040e-01, 8.5525e-01, 4.9024e-02,\n",
       "         9.1439e-01, 2.3205e-02, 2.9997e-02, 1.4161e-01, 5.4257e-01, 4.7110e-01,\n",
       "         5.5295e-01, 9.0646e-02, 7.1965e-01, 3.3582e-01, 5.7370e-01, 2.0620e-01,\n",
       "         8.6495e-01, 8.5343e-01, 4.3251e-01, 8.0607e-01, 9.0338e-01, 8.9296e-01,\n",
       "         4.6476e-01, 4.2974e-01, 7.0296e-01, 9.6169e-01, 6.4877e-01, 8.7568e-01,\n",
       "         2.3082e-01, 3.6488e-01, 1.7528e-01, 6.9304e-01, 2.6273e-01, 2.0417e-01,\n",
       "         2.9758e-01, 6.6779e-01, 7.2138e-01, 2.7512e-01, 7.2340e-01, 1.9000e-01,\n",
       "         1.4749e-01, 1.6018e-01, 2.1884e-02, 8.0242e-01, 6.7141e-01, 2.3468e-01,\n",
       "         7.2762e-01, 3.7536e-01],\n",
       "        [3.6722e-01, 6.1954e-01, 2.6733e-01, 9.8692e-01, 7.0265e-01, 3.0060e-01,\n",
       "         1.4860e-01, 2.6559e-01, 3.4733e-01, 4.3666e-02, 3.8843e-01, 7.4378e-01,\n",
       "         5.8173e-01, 9.2892e-01, 5.9977e-01, 5.0728e-01, 1.2327e-01, 1.8557e-01,\n",
       "         2.9949e-01, 3.8563e-03, 1.5369e-01, 6.5639e-01, 7.1843e-01, 5.3115e-01,\n",
       "         1.4270e-01, 4.0285e-01, 8.4160e-01, 4.4061e-01, 8.1586e-02, 6.5994e-01,\n",
       "         6.1001e-01, 6.2855e-01, 1.2842e-01, 7.4026e-01, 5.1458e-01, 6.5984e-01,\n",
       "         5.3383e-01, 8.1909e-02, 1.0372e-02, 7.1512e-01, 7.8931e-01, 6.0714e-02,\n",
       "         4.5561e-01, 3.9058e-01, 4.2661e-01, 6.4934e-01, 9.2875e-01, 3.2765e-01,\n",
       "         8.2002e-01, 1.3512e-01, 2.6822e-01, 6.9394e-02, 6.1388e-01, 5.8394e-01,\n",
       "         3.8140e-01, 5.1514e-01, 5.7240e-01, 1.0473e-01, 4.1952e-02, 9.5726e-01,\n",
       "         1.1242e-01, 6.1956e-01],\n",
       "        [4.9919e-02, 9.8319e-01, 8.8738e-01, 9.8270e-01, 3.7739e-01, 2.8632e-01,\n",
       "         3.5410e-02, 3.2626e-01, 4.2064e-01, 5.7277e-01, 8.0087e-01, 5.6953e-01,\n",
       "         9.8668e-01, 7.2570e-01, 7.3029e-01, 9.4015e-01, 9.8796e-01, 5.6078e-01,\n",
       "         8.5109e-01, 3.6488e-01, 9.8593e-01, 1.4435e-01, 9.6715e-01, 8.6096e-01,\n",
       "         2.5364e-01, 7.6570e-01, 9.7534e-01, 8.4576e-01, 3.9462e-01, 4.5563e-01,\n",
       "         4.0746e-01, 2.0022e-01, 1.0119e-01, 7.9382e-01, 6.9017e-01, 8.1643e-02,\n",
       "         6.5121e-01, 8.8000e-01, 8.9451e-01, 2.4915e-01, 2.6449e-01, 8.0961e-01,\n",
       "         3.7568e-01, 5.5203e-01, 4.6961e-01, 7.3205e-01, 8.3905e-01, 6.0556e-01,\n",
       "         3.8516e-01, 5.5808e-01, 2.8417e-01, 2.6895e-01, 6.7588e-02, 7.5620e-01,\n",
       "         4.1012e-01, 7.6033e-01, 2.1682e-01, 1.9940e-01, 3.9568e-01, 4.9448e-01,\n",
       "         7.5336e-01, 4.9672e-01],\n",
       "        [1.3585e-01, 7.6376e-01, 7.1237e-01, 5.5988e-01, 4.4526e-02, 4.7226e-01,\n",
       "         3.5791e-01, 9.8862e-01, 8.1536e-01, 8.7920e-02, 8.8985e-01, 6.2304e-01,\n",
       "         4.1585e-01, 2.3679e-01, 6.5509e-01, 8.6691e-01, 1.7439e-01, 7.2106e-01,\n",
       "         9.4471e-02, 4.9478e-01, 3.4320e-01, 7.7775e-02, 5.9106e-01, 2.9725e-01,\n",
       "         8.9870e-01, 6.3342e-01, 4.2752e-01, 5.5689e-01, 1.0443e-01, 6.4531e-01,\n",
       "         4.0799e-01, 4.9344e-01, 6.2381e-01, 2.3402e-01, 3.6649e-01, 3.8877e-01,\n",
       "         1.1220e-01, 2.7260e-01, 8.1764e-01, 3.0897e-01, 5.3839e-01, 3.3809e-01,\n",
       "         9.1145e-01, 7.4003e-01, 4.5703e-01, 2.1333e-01, 8.8401e-01, 1.3179e-01,\n",
       "         7.2661e-01, 2.7456e-01, 4.3072e-02, 7.2500e-01, 1.7801e-01, 6.1437e-01,\n",
       "         8.4623e-01, 4.3556e-01, 6.7303e-01, 3.7293e-01, 8.6600e-01, 5.7086e-01,\n",
       "         1.8680e-01, 8.0998e-01],\n",
       "        [7.3872e-01, 9.8578e-01, 8.4271e-01, 3.8883e-02, 4.4759e-01, 5.3321e-02,\n",
       "         1.8522e-01, 9.1682e-01, 5.1231e-01, 8.6930e-01, 3.8718e-01, 9.2173e-01,\n",
       "         1.4877e-01, 7.8247e-01, 6.5250e-02, 1.3328e-01, 8.9819e-01, 2.0463e-01,\n",
       "         4.4452e-01, 6.5197e-01, 5.1680e-01, 4.3261e-01, 5.9346e-01, 5.1092e-01,\n",
       "         5.2705e-01, 1.5524e-02, 8.4122e-01, 3.9336e-01, 4.3358e-01, 5.2034e-01,\n",
       "         5.5389e-01, 2.6923e-01, 1.3525e-01, 4.4269e-01, 5.1309e-01, 4.6577e-01,\n",
       "         2.1872e-01, 7.2909e-01, 6.4321e-01, 6.4623e-01, 6.4631e-01, 1.3068e-01,\n",
       "         3.6016e-01, 1.4738e-01, 5.5238e-01, 7.4572e-01, 5.8483e-01, 4.6056e-01,\n",
       "         6.6055e-02, 6.9655e-02, 6.1856e-01, 7.0396e-01, 4.4940e-01, 9.9985e-01,\n",
       "         9.9899e-01, 5.9550e-01, 5.8376e-01, 9.1184e-01, 9.7502e-01, 9.4244e-01,\n",
       "         4.2971e-01, 3.4733e-01]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "oriental-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5965, 0.3781, 0.1513, 0.1158, 0.6886, 0.8067, 0.6663, 0.5890, 0.6116,\n",
       "        0.2014, 0.5506, 0.6796, 0.4135, 0.6969, 0.2634, 0.0686, 0.5530, 0.6165,\n",
       "        0.3308, 0.3186, 0.9145, 0.2548, 0.1336, 0.4622, 0.1730, 0.8474, 0.4329,\n",
       "        0.7840, 0.1798, 0.1501, 0.1951, 0.3263, 0.5000, 0.9071, 0.5895, 0.7884,\n",
       "        0.9110, 0.7678, 0.2392, 0.0749, 0.3178, 0.3750, 0.0865, 0.0119, 0.7775,\n",
       "        0.8067, 0.7773, 0.1547, 0.7555, 0.2847, 0.8508, 0.3132, 0.1638, 0.2782,\n",
       "        0.1863, 0.8209, 0.3369, 0.6736, 0.1242, 0.7732, 0.4156, 0.9000])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st[15][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "parliamentary-multimedia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9104, 0.3321, 0.1306,  ..., 0.6653, 0.6279, 0.8036],\n",
       "         [0.8869, 0.3657, 0.0304,  ..., 0.4979, 0.1830, 0.4993],\n",
       "         [0.6165, 0.2715, 0.8923,  ..., 0.6384, 0.1819, 0.5126],\n",
       "         ...,\n",
       "         [0.2963, 0.0012, 0.9134,  ..., 0.9108, 0.8808, 0.3757],\n",
       "         [0.0814, 0.1206, 0.6598,  ..., 0.7502, 0.9866, 0.4247],\n",
       "         [0.6967, 0.8306, 0.0088,  ..., 0.7491, 0.5935, 0.8041]],\n",
       "\n",
       "        [[0.2160, 0.3457, 0.9077,  ..., 0.9212, 0.5426, 0.7474],\n",
       "         [0.8171, 0.7326, 0.5667,  ..., 0.3648, 0.7438, 0.2154],\n",
       "         [0.5241, 0.8059, 0.3340,  ..., 0.0410, 0.5450, 0.7202],\n",
       "         ...,\n",
       "         [0.5238, 0.0643, 0.9787,  ..., 0.8499, 0.6198, 0.0088],\n",
       "         [0.7577, 0.6400, 0.7444,  ..., 0.6953, 0.2089, 0.6021],\n",
       "         [0.7468, 0.4580, 0.5644,  ..., 0.5501, 0.0760, 0.1754]],\n",
       "\n",
       "        [[0.4732, 0.0541, 0.8589,  ..., 0.3244, 0.0657, 0.6186],\n",
       "         [0.5070, 0.3726, 0.9182,  ..., 0.3969, 0.9317, 0.8615],\n",
       "         [0.9636, 0.5885, 0.7955,  ..., 0.2294, 0.0740, 0.4479],\n",
       "         ...,\n",
       "         [0.3527, 0.0747, 0.8152,  ..., 0.7337, 0.1893, 0.9477],\n",
       "         [0.4064, 0.6608, 0.2005,  ..., 0.0973, 0.8434, 0.0915],\n",
       "         [0.0729, 0.4212, 0.7901,  ..., 0.5766, 0.9252, 0.1981]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8640, 0.2474, 0.4760,  ..., 0.4446, 0.4904, 0.0204],\n",
       "         [0.5353, 0.7195, 0.3552,  ..., 0.2636, 0.8357, 0.5129],\n",
       "         [0.2196, 0.6607, 0.6873,  ..., 0.3981, 0.8945, 0.9323],\n",
       "         ...,\n",
       "         [0.7763, 0.9219, 0.1009,  ..., 0.0082, 0.7228, 0.5085],\n",
       "         [0.1191, 0.8822, 0.6673,  ..., 0.7349, 0.5101, 0.3749],\n",
       "         [0.8604, 0.5703, 0.6126,  ..., 0.8990, 0.8682, 0.1267]],\n",
       "\n",
       "        [[0.9685, 0.1142, 0.5163,  ..., 0.1450, 0.6526, 0.7560],\n",
       "         [0.3081, 0.4097, 0.4467,  ..., 0.9739, 0.8607, 0.6509],\n",
       "         [0.1808, 0.0415, 0.5030,  ..., 0.0774, 0.5738, 0.0236],\n",
       "         ...,\n",
       "         [0.8384, 0.4022, 0.9674,  ..., 0.2113, 0.6274, 0.6356],\n",
       "         [0.2183, 0.7245, 0.3289,  ..., 0.5174, 0.5342, 0.2552],\n",
       "         [0.0374, 0.6958, 0.7591,  ..., 0.1668, 0.3552, 0.6940]],\n",
       "\n",
       "        [[0.3865, 0.5561, 0.1239,  ..., 0.9296, 0.8557, 0.0671],\n",
       "         [0.7580, 0.5736, 0.0246,  ..., 0.3377, 0.4163, 0.3123],\n",
       "         [0.3982, 0.9257, 0.6756,  ..., 0.1197, 0.6815, 0.4280],\n",
       "         ...,\n",
       "         [0.5463, 0.5601, 0.3346,  ..., 0.6354, 0.8401, 0.8033],\n",
       "         [0.5886, 0.2272, 0.5506,  ..., 0.2692, 0.1971, 0.1922],\n",
       "         [0.2097, 0.1733, 0.2604,  ..., 0.6848, 0.2261, 0.2846]]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = torch.rand(12,16,11)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "shared-trail",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.rand(16,7,2).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "attended-integer",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Index tensor must have the same number of dimensions as input tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-474809caf343>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m: Index tensor must have the same number of dimensions as input tensor"
     ]
    }
   ],
   "source": [
    "a.gather(0, torch.LongTensor([16,7,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "relevant-accuracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[[ 2,  5],\n",
    "         [11, 11],\n",
    "         [ 8,  2],\n",
    "         [10,  6],\n",
    "         [ 3,  9],\n",
    "         [ 4,  1],\n",
    "         [ 5,  8]],\n",
    "\n",
    "        [[ 1,  5],\n",
    "         [ 5,  7],\n",
    "         [ 8,  2],\n",
    "         [ 0, 10],\n",
    "         [10,  6],\n",
    "         [11,  1],\n",
    "         [ 7,  4]],\n",
    "\n",
    "        [[ 0,  7],\n",
    "         [10,  2],\n",
    "         [ 7,  9],\n",
    "         [ 6,  5],\n",
    "         [ 1, 11],\n",
    "         [ 3, 10],\n",
    "         [ 8,  6]],\n",
    "\n",
    "        [[ 1,  9],\n",
    "         [ 5,  3],\n",
    "         [ 4, 10],\n",
    "         [ 3, 11],\n",
    "         [ 8,  6],\n",
    "         [11,  5],\n",
    "         [ 7,  8]],\n",
    "\n",
    "        [[ 7,  2],\n",
    "         [11,  7],\n",
    "         [ 3,  8],\n",
    "         [10, 10],\n",
    "         [ 6,  9],\n",
    "         [ 4,  6],\n",
    "         [ 8,  1]],\n",
    "\n",
    "        [[ 9,  5],\n",
    "         [10,  5],\n",
    "         [11,  5],\n",
    "         [ 0,  6],\n",
    "         [ 1,  6],\n",
    "         [ 2,  6],\n",
    "         [ 3,  6]],\n",
    "\n",
    "        [[ 0,  1],\n",
    "         [11,  4],\n",
    "         [ 2,  8],\n",
    "         [ 5, 11],\n",
    "         [ 9, 10],\n",
    "         [ 4,  7],\n",
    "         [ 3,  3]],\n",
    "\n",
    "        [[ 8, 10],\n",
    "         [ 0,  1],\n",
    "         [ 3,  6],\n",
    "         [10,  5],\n",
    "         [ 6, 11],\n",
    "         [11,  3],\n",
    "         [ 7,  4]],\n",
    "\n",
    "        [[10,  2],\n",
    "         [ 1,  5],\n",
    "         [11,  9],\n",
    "         [ 4,  1],\n",
    "         [ 3,  4],\n",
    "         [ 5,  6],\n",
    "         [ 7,  3]],\n",
    "\n",
    "        [[ 5,  1],\n",
    "         [ 1,  9],\n",
    "         [ 2, 11],\n",
    "         [ 3,  2],\n",
    "         [ 6,  8],\n",
    "         [11,  7],\n",
    "         [ 9,  4]],\n",
    "\n",
    "        [[10,  5],\n",
    "         [ 1,  4],\n",
    "         [11,  3],\n",
    "         [ 4,  2],\n",
    "         [ 9,  9],\n",
    "         [ 3,  8],\n",
    "         [ 8,  6]],\n",
    "\n",
    "        [[ 3,  5],\n",
    "         [ 7,  6],\n",
    "         [ 4,  9],\n",
    "         [ 1,  7],\n",
    "         [ 5,  1],\n",
    "         [ 6,  8],\n",
    "         [ 0,  4]],\n",
    "\n",
    "        [[ 7,  6],\n",
    "         [ 9,  4],\n",
    "         [10, 10],\n",
    "         [ 1,  9],\n",
    "         [ 5,  3],\n",
    "         [ 2, 11],\n",
    "         [ 4,  8]],\n",
    "\n",
    "        [[10,  6],\n",
    "         [ 2,  7],\n",
    "         [ 4, 11],\n",
    "         [ 9,  8],\n",
    "         [ 1,  3],\n",
    "         [ 7,  5],\n",
    "         [ 0,  2]],\n",
    "\n",
    "        [[ 4,  2],\n",
    "         [ 6,  1],\n",
    "         [ 2,  6],\n",
    "         [ 1, 10],\n",
    "         [ 8,  5],\n",
    "         [ 0, 11],\n",
    "         [ 7,  4]],\n",
    "\n",
    "        [[ 5,  7],\n",
    "         [ 2,  7],\n",
    "         [ 8,  7],\n",
    "         [ 1, 10],\n",
    "         [10, 10],\n",
    "         [11,  7],\n",
    "         [ 4, 10]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "involved-samuel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 7, 2])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fifteen-payment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2, 11,  8, 10,  3,  4,  5],\n",
       "         [ 5, 11,  2,  6,  9,  1,  8]],\n",
       "\n",
       "        [[ 1,  5,  8,  0, 10, 11,  7],\n",
       "         [ 5,  7,  2, 10,  6,  1,  4]],\n",
       "\n",
       "        [[ 0, 10,  7,  6,  1,  3,  8],\n",
       "         [ 7,  2,  9,  5, 11, 10,  6]],\n",
       "\n",
       "        [[ 1,  5,  4,  3,  8, 11,  7],\n",
       "         [ 9,  3, 10, 11,  6,  5,  8]],\n",
       "\n",
       "        [[ 7, 11,  3, 10,  6,  4,  8],\n",
       "         [ 2,  7,  8, 10,  9,  6,  1]],\n",
       "\n",
       "        [[ 9, 10, 11,  0,  1,  2,  3],\n",
       "         [ 5,  5,  5,  6,  6,  6,  6]],\n",
       "\n",
       "        [[ 0, 11,  2,  5,  9,  4,  3],\n",
       "         [ 1,  4,  8, 11, 10,  7,  3]],\n",
       "\n",
       "        [[ 8,  0,  3, 10,  6, 11,  7],\n",
       "         [10,  1,  6,  5, 11,  3,  4]],\n",
       "\n",
       "        [[10,  1, 11,  4,  3,  5,  7],\n",
       "         [ 2,  5,  9,  1,  4,  6,  3]],\n",
       "\n",
       "        [[ 5,  1,  2,  3,  6, 11,  9],\n",
       "         [ 1,  9, 11,  2,  8,  7,  4]],\n",
       "\n",
       "        [[10,  1, 11,  4,  9,  3,  8],\n",
       "         [ 5,  4,  3,  2,  9,  8,  6]],\n",
       "\n",
       "        [[ 3,  7,  4,  1,  5,  6,  0],\n",
       "         [ 5,  6,  9,  7,  1,  8,  4]],\n",
       "\n",
       "        [[ 7,  9, 10,  1,  5,  2,  4],\n",
       "         [ 6,  4, 10,  9,  3, 11,  8]],\n",
       "\n",
       "        [[10,  2,  4,  9,  1,  7,  0],\n",
       "         [ 6,  7, 11,  8,  3,  5,  2]],\n",
       "\n",
       "        [[ 4,  6,  2,  1,  8,  0,  7],\n",
       "         [ 2,  1,  6, 10,  5, 11,  4]],\n",
       "\n",
       "        [[ 5,  2,  8,  1, 10, 11,  4],\n",
       "         [ 7,  7,  7, 10, 10,  7, 10]]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = a.transpose(1,2)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "north-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = a[:,0]\n",
    "l = a[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "direct-advisory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2, 11,  8, 10,  3,  4,  5],\n",
       "        [ 1,  5,  8,  0, 10, 11,  7],\n",
       "        [ 0, 10,  7,  6,  1,  3,  8],\n",
       "        [ 1,  5,  4,  3,  8, 11,  7],\n",
       "        [ 7, 11,  3, 10,  6,  4,  8],\n",
       "        [ 9, 10, 11,  0,  1,  2,  3],\n",
       "        [ 0, 11,  2,  5,  9,  4,  3],\n",
       "        [ 8,  0,  3, 10,  6, 11,  7],\n",
       "        [10,  1, 11,  4,  3,  5,  7],\n",
       "        [ 5,  1,  2,  3,  6, 11,  9],\n",
       "        [10,  1, 11,  4,  9,  3,  8],\n",
       "        [ 3,  7,  4,  1,  5,  6,  0],\n",
       "        [ 7,  9, 10,  1,  5,  2,  4],\n",
       "        [10,  2,  4,  9,  1,  7,  0],\n",
       "        [ 4,  6,  2,  1,  8,  0,  7],\n",
       "        [ 5,  2,  8,  1, 10, 11,  4]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "regular-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 11,  2,  6,  9,  1,  8],\n",
       "        [ 5,  7,  2, 10,  6,  1,  4],\n",
       "        [ 7,  2,  9,  5, 11, 10,  6],\n",
       "        [ 9,  3, 10, 11,  6,  5,  8],\n",
       "        [ 2,  7,  8, 10,  9,  6,  1],\n",
       "        [ 5,  5,  5,  6,  6,  6,  6],\n",
       "        [ 1,  4,  8, 11, 10,  7,  3],\n",
       "        [10,  1,  6,  5, 11,  3,  4],\n",
       "        [ 2,  5,  9,  1,  4,  6,  3],\n",
       "        [ 1,  9, 11,  2,  8,  7,  4],\n",
       "        [ 5,  4,  3,  2,  9,  8,  6],\n",
       "        [ 5,  6,  9,  7,  1,  8,  4],\n",
       "        [ 6,  4, 10,  9,  3, 11,  8],\n",
       "        [ 6,  7, 11,  8,  3,  5,  2],\n",
       "        [ 2,  1,  6, 10,  5, 11,  4],\n",
       "        [ 7,  7,  7, 10, 10,  7, 10]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "figured-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = l - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-beads",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "thirty-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,1] = a[:,1] - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "silver-shaft",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2, 11,  8, 10,  3,  4,  5],\n",
       "         [ 4, 10,  1,  5,  8,  0,  7]],\n",
       "\n",
       "        [[ 1,  5,  8,  0, 10, 11,  7],\n",
       "         [ 4,  6,  1,  9,  5,  0,  3]],\n",
       "\n",
       "        [[ 0, 10,  7,  6,  1,  3,  8],\n",
       "         [ 6,  1,  8,  4, 10,  9,  5]],\n",
       "\n",
       "        [[ 1,  5,  4,  3,  8, 11,  7],\n",
       "         [ 8,  2,  9, 10,  5,  4,  7]],\n",
       "\n",
       "        [[ 7, 11,  3, 10,  6,  4,  8],\n",
       "         [ 1,  6,  7,  9,  8,  5,  0]],\n",
       "\n",
       "        [[ 9, 10, 11,  0,  1,  2,  3],\n",
       "         [ 4,  4,  4,  5,  5,  5,  5]],\n",
       "\n",
       "        [[ 0, 11,  2,  5,  9,  4,  3],\n",
       "         [ 0,  3,  7, 10,  9,  6,  2]],\n",
       "\n",
       "        [[ 8,  0,  3, 10,  6, 11,  7],\n",
       "         [ 9,  0,  5,  4, 10,  2,  3]],\n",
       "\n",
       "        [[10,  1, 11,  4,  3,  5,  7],\n",
       "         [ 1,  4,  8,  0,  3,  5,  2]],\n",
       "\n",
       "        [[ 5,  1,  2,  3,  6, 11,  9],\n",
       "         [ 0,  8, 10,  1,  7,  6,  3]],\n",
       "\n",
       "        [[10,  1, 11,  4,  9,  3,  8],\n",
       "         [ 4,  3,  2,  1,  8,  7,  5]],\n",
       "\n",
       "        [[ 3,  7,  4,  1,  5,  6,  0],\n",
       "         [ 4,  5,  8,  6,  0,  7,  3]],\n",
       "\n",
       "        [[ 7,  9, 10,  1,  5,  2,  4],\n",
       "         [ 5,  3,  9,  8,  2, 10,  7]],\n",
       "\n",
       "        [[10,  2,  4,  9,  1,  7,  0],\n",
       "         [ 5,  6, 10,  7,  2,  4,  1]],\n",
       "\n",
       "        [[ 4,  6,  2,  1,  8,  0,  7],\n",
       "         [ 1,  0,  5,  9,  4, 10,  3]],\n",
       "\n",
       "        [[ 5,  2,  8,  1, 10, 11,  4],\n",
       "         [ 6,  6,  6,  9,  9,  6,  9]]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "closed-implementation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 11])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "bright-husband",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4852, 0.6873, 0.7841, 0.8713, 0.2902, 0.7676, 0.0334, 0.0519, 0.3088,\n",
       "        0.8429, 0.1501, 0.0591, 0.9100, 0.6772, 0.8635, 0.9863])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[2].transpose(0,1)[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "miniature-township",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4732, 0.0541, 0.8589, 0.2897, 0.1120, 0.5677, 0.7250, 0.4852, 0.3244,\n",
       "         0.0657, 0.6186],\n",
       "        [0.5070, 0.3726, 0.9182, 0.7436, 0.3511, 0.2861, 0.5697, 0.6873, 0.3969,\n",
       "         0.9317, 0.8615],\n",
       "        [0.9636, 0.5885, 0.7955, 0.8832, 0.2987, 0.6666, 0.0843, 0.7841, 0.2294,\n",
       "         0.0740, 0.4479],\n",
       "        [0.2490, 0.2594, 0.6460, 0.0783, 0.9437, 0.7117, 0.3293, 0.8713, 0.4490,\n",
       "         0.7669, 0.6650],\n",
       "        [0.6362, 0.2256, 0.5302, 0.9728, 0.6515, 0.0619, 0.2034, 0.2902, 0.8987,\n",
       "         0.6412, 0.5201],\n",
       "        [0.7204, 0.4928, 0.9359, 0.6027, 0.6712, 0.2136, 0.0554, 0.7676, 0.6041,\n",
       "         0.8705, 0.3043],\n",
       "        [0.3892, 0.6285, 0.3813, 0.3496, 0.9412, 0.4949, 0.0850, 0.0334, 0.6270,\n",
       "         0.9636, 0.7937],\n",
       "        [0.8418, 0.8817, 0.8408, 0.0415, 0.3436, 0.7089, 0.1910, 0.0519, 0.5899,\n",
       "         0.3183, 0.8764],\n",
       "        [0.6120, 0.3214, 0.3186, 0.1770, 0.1759, 0.0188, 0.9392, 0.3088, 0.3144,\n",
       "         0.2818, 0.4104],\n",
       "        [0.4419, 0.0804, 0.5903, 0.8253, 0.0791, 0.1645, 0.7560, 0.8429, 0.3919,\n",
       "         0.5409, 0.8256],\n",
       "        [0.5984, 0.2417, 0.0779, 0.6632, 0.5274, 0.7114, 0.6709, 0.1501, 0.3932,\n",
       "         0.5247, 0.8857],\n",
       "        [0.1233, 0.2847, 0.4079, 0.2593, 0.3213, 0.1970, 0.1958, 0.0591, 0.0772,\n",
       "         0.4422, 0.9793],\n",
       "        [0.2805, 0.5816, 0.4995, 0.8494, 0.8699, 0.7854, 0.2467, 0.9100, 0.2380,\n",
       "         0.3752, 0.8999],\n",
       "        [0.3527, 0.0747, 0.8152, 0.3972, 0.8899, 0.2025, 0.0767, 0.6772, 0.7337,\n",
       "         0.1893, 0.9477],\n",
       "        [0.4064, 0.6608, 0.2005, 0.7324, 0.3556, 0.7806, 0.5774, 0.8635, 0.0973,\n",
       "         0.8434, 0.0915],\n",
       "        [0.0729, 0.4212, 0.7901, 0.7599, 0.2853, 0.8581, 0.3514, 0.9863, 0.5766,\n",
       "         0.9252, 0.1981]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "suspected-capacity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9104, 0.3321, 0.1306,  ..., 0.6653, 0.6279, 0.8036],\n",
       "         [0.8869, 0.3657, 0.0304,  ..., 0.4979, 0.1830, 0.4993],\n",
       "         [0.6165, 0.2715, 0.8923,  ..., 0.6384, 0.1819, 0.5126],\n",
       "         ...,\n",
       "         [0.2963, 0.0012, 0.9134,  ..., 0.9108, 0.8808, 0.3757],\n",
       "         [0.0814, 0.1206, 0.6598,  ..., 0.7502, 0.9866, 0.4247],\n",
       "         [0.6967, 0.8306, 0.0088,  ..., 0.7491, 0.5935, 0.8041]],\n",
       "\n",
       "        [[0.2160, 0.3457, 0.9077,  ..., 0.9212, 0.5426, 0.7474],\n",
       "         [0.8171, 0.7326, 0.5667,  ..., 0.3648, 0.7438, 0.2154],\n",
       "         [0.5241, 0.8059, 0.3340,  ..., 0.0410, 0.5450, 0.7202],\n",
       "         ...,\n",
       "         [0.5238, 0.0643, 0.9787,  ..., 0.8499, 0.6198, 0.0088],\n",
       "         [0.7577, 0.6400, 0.7444,  ..., 0.6953, 0.2089, 0.6021],\n",
       "         [0.7468, 0.4580, 0.5644,  ..., 0.5501, 0.0760, 0.1754]],\n",
       "\n",
       "        [[0.4732, 0.0541, 0.8589,  ..., 0.3244, 0.0657, 0.6186],\n",
       "         [0.5070, 0.3726, 0.9182,  ..., 0.3969, 0.9317, 0.8615],\n",
       "         [0.9636, 0.5885, 0.7955,  ..., 0.2294, 0.0740, 0.4479],\n",
       "         ...,\n",
       "         [0.3527, 0.0747, 0.8152,  ..., 0.7337, 0.1893, 0.9477],\n",
       "         [0.4064, 0.6608, 0.2005,  ..., 0.0973, 0.8434, 0.0915],\n",
       "         [0.0729, 0.4212, 0.7901,  ..., 0.5766, 0.9252, 0.1981]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8640, 0.2474, 0.4760,  ..., 0.4446, 0.4904, 0.0204],\n",
       "         [0.5353, 0.7195, 0.3552,  ..., 0.2636, 0.8357, 0.5129],\n",
       "         [0.2196, 0.6607, 0.6873,  ..., 0.3981, 0.8945, 0.9323],\n",
       "         ...,\n",
       "         [0.7763, 0.9219, 0.1009,  ..., 0.0082, 0.7228, 0.5085],\n",
       "         [0.1191, 0.8822, 0.6673,  ..., 0.7349, 0.5101, 0.3749],\n",
       "         [0.8604, 0.5703, 0.6126,  ..., 0.8990, 0.8682, 0.1267]],\n",
       "\n",
       "        [[0.9685, 0.1142, 0.5163,  ..., 0.1450, 0.6526, 0.7560],\n",
       "         [0.3081, 0.4097, 0.4467,  ..., 0.9739, 0.8607, 0.6509],\n",
       "         [0.1808, 0.0415, 0.5030,  ..., 0.0774, 0.5738, 0.0236],\n",
       "         ...,\n",
       "         [0.8384, 0.4022, 0.9674,  ..., 0.2113, 0.6274, 0.6356],\n",
       "         [0.2183, 0.7245, 0.3289,  ..., 0.5174, 0.5342, 0.2552],\n",
       "         [0.0374, 0.6958, 0.7591,  ..., 0.1668, 0.3552, 0.6940]],\n",
       "\n",
       "        [[0.3865, 0.5561, 0.1239,  ..., 0.9296, 0.8557, 0.0671],\n",
       "         [0.7580, 0.5736, 0.0246,  ..., 0.3377, 0.4163, 0.3123],\n",
       "         [0.3982, 0.9257, 0.6756,  ..., 0.1197, 0.6815, 0.4280],\n",
       "         ...,\n",
       "         [0.5463, 0.5601, 0.3346,  ..., 0.6354, 0.8401, 0.8033],\n",
       "         [0.5886, 0.2272, 0.5506,  ..., 0.2692, 0.1971, 0.1922],\n",
       "         [0.2097, 0.1733, 0.2604,  ..., 0.6848, 0.2261, 0.2846]]])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "alert-fifth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2, 11,  8, 10,  3,  4,  5],\n",
       "         [ 4, 10,  1,  5,  8,  0,  7]],\n",
       "\n",
       "        [[ 1,  5,  8,  0, 10, 11,  7],\n",
       "         [ 4,  6,  1,  9,  5,  0,  3]],\n",
       "\n",
       "        [[ 0, 10,  7,  6,  1,  3,  8],\n",
       "         [ 6,  1,  8,  4, 10,  9,  5]],\n",
       "\n",
       "        [[ 1,  5,  4,  3,  8, 11,  7],\n",
       "         [ 8,  2,  9, 10,  5,  4,  7]],\n",
       "\n",
       "        [[ 7, 11,  3, 10,  6,  4,  8],\n",
       "         [ 1,  6,  7,  9,  8,  5,  0]],\n",
       "\n",
       "        [[ 9, 10, 11,  0,  1,  2,  3],\n",
       "         [ 4,  4,  4,  5,  5,  5,  5]],\n",
       "\n",
       "        [[ 0, 11,  2,  5,  9,  4,  3],\n",
       "         [ 0,  3,  7, 10,  9,  6,  2]],\n",
       "\n",
       "        [[ 8,  0,  3, 10,  6, 11,  7],\n",
       "         [ 9,  0,  5,  4, 10,  2,  3]],\n",
       "\n",
       "        [[10,  1, 11,  4,  3,  5,  7],\n",
       "         [ 1,  4,  8,  0,  3,  5,  2]],\n",
       "\n",
       "        [[ 5,  1,  2,  3,  6, 11,  9],\n",
       "         [ 0,  8, 10,  1,  7,  6,  3]],\n",
       "\n",
       "        [[10,  1, 11,  4,  9,  3,  8],\n",
       "         [ 4,  3,  2,  1,  8,  7,  5]],\n",
       "\n",
       "        [[ 3,  7,  4,  1,  5,  6,  0],\n",
       "         [ 4,  5,  8,  6,  0,  7,  3]],\n",
       "\n",
       "        [[ 7,  9, 10,  1,  5,  2,  4],\n",
       "         [ 5,  3,  9,  8,  2, 10,  7]],\n",
       "\n",
       "        [[10,  2,  4,  9,  1,  7,  0],\n",
       "         [ 5,  6, 10,  7,  2,  4,  1]],\n",
       "\n",
       "        [[ 4,  6,  2,  1,  8,  0,  7],\n",
       "         [ 1,  0,  5,  9,  4, 10,  3]],\n",
       "\n",
       "        [[ 5,  2,  8,  1, 10, 11,  4],\n",
       "         [ 6,  6,  6,  9,  9,  6,  9]]])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "neutral-sherman",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = a.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "seven-introduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  4],\n",
       "         [11, 10],\n",
       "         [ 8,  1],\n",
       "         [10,  5],\n",
       "         [ 3,  8],\n",
       "         [ 4,  0],\n",
       "         [ 5,  7]],\n",
       "\n",
       "        [[ 1,  4],\n",
       "         [ 5,  6],\n",
       "         [ 8,  1],\n",
       "         [ 0,  9],\n",
       "         [10,  5],\n",
       "         [11,  0],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[ 0,  6],\n",
       "         [10,  1],\n",
       "         [ 7,  8],\n",
       "         [ 6,  4],\n",
       "         [ 1, 10],\n",
       "         [ 3,  9],\n",
       "         [ 8,  5]],\n",
       "\n",
       "        [[ 1,  8],\n",
       "         [ 5,  2],\n",
       "         [ 4,  9],\n",
       "         [ 3, 10],\n",
       "         [ 8,  5],\n",
       "         [11,  4],\n",
       "         [ 7,  7]],\n",
       "\n",
       "        [[ 7,  1],\n",
       "         [11,  6],\n",
       "         [ 3,  7],\n",
       "         [10,  9],\n",
       "         [ 6,  8],\n",
       "         [ 4,  5],\n",
       "         [ 8,  0]],\n",
       "\n",
       "        [[ 9,  4],\n",
       "         [10,  4],\n",
       "         [11,  4],\n",
       "         [ 0,  5],\n",
       "         [ 1,  5],\n",
       "         [ 2,  5],\n",
       "         [ 3,  5]],\n",
       "\n",
       "        [[ 0,  0],\n",
       "         [11,  3],\n",
       "         [ 2,  7],\n",
       "         [ 5, 10],\n",
       "         [ 9,  9],\n",
       "         [ 4,  6],\n",
       "         [ 3,  2]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [ 0,  0],\n",
       "         [ 3,  5],\n",
       "         [10,  4],\n",
       "         [ 6, 10],\n",
       "         [11,  2],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[10,  1],\n",
       "         [ 1,  4],\n",
       "         [11,  8],\n",
       "         [ 4,  0],\n",
       "         [ 3,  3],\n",
       "         [ 5,  5],\n",
       "         [ 7,  2]],\n",
       "\n",
       "        [[ 5,  0],\n",
       "         [ 1,  8],\n",
       "         [ 2, 10],\n",
       "         [ 3,  1],\n",
       "         [ 6,  7],\n",
       "         [11,  6],\n",
       "         [ 9,  3]],\n",
       "\n",
       "        [[10,  4],\n",
       "         [ 1,  3],\n",
       "         [11,  2],\n",
       "         [ 4,  1],\n",
       "         [ 9,  8],\n",
       "         [ 3,  7],\n",
       "         [ 8,  5]],\n",
       "\n",
       "        [[ 3,  4],\n",
       "         [ 7,  5],\n",
       "         [ 4,  8],\n",
       "         [ 1,  6],\n",
       "         [ 5,  0],\n",
       "         [ 6,  7],\n",
       "         [ 0,  3]],\n",
       "\n",
       "        [[ 7,  5],\n",
       "         [ 9,  3],\n",
       "         [10,  9],\n",
       "         [ 1,  8],\n",
       "         [ 5,  2],\n",
       "         [ 2, 10],\n",
       "         [ 4,  7]],\n",
       "\n",
       "        [[10,  5],\n",
       "         [ 2,  6],\n",
       "         [ 4, 10],\n",
       "         [ 9,  7],\n",
       "         [ 1,  2],\n",
       "         [ 7,  4],\n",
       "         [ 0,  1]],\n",
       "\n",
       "        [[ 4,  1],\n",
       "         [ 6,  0],\n",
       "         [ 2,  5],\n",
       "         [ 1,  9],\n",
       "         [ 8,  4],\n",
       "         [ 0, 10],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 2,  6],\n",
       "         [ 8,  6],\n",
       "         [ 1,  9],\n",
       "         [10,  9],\n",
       "         [11,  6],\n",
       "         [ 4,  9]]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "indian-providence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16, 11])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "perceived-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "occasional-checkout",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 11, 16])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "stretch-ranking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 7, 16])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = []\n",
    "for act in a:\n",
    "    batch = []\n",
    "    for sub_act in act:\n",
    "        batch.append(r[sub_act[0]][sub_act[1]])\n",
    "    q.append(torch.stack(batch))\n",
    "torch.stack(q).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "false-victorian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8126, 0.4204, 0.9744, 0.4650, 0.3760, 0.8659, 0.1643, 0.4925, 0.5820,\n",
       "        0.6886, 0.9918, 0.9626, 0.0045, 0.0376, 0.3990, 0.2539])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "beginning-literature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4732, 0.5070, 0.9636, 0.2490, 0.6362, 0.7204, 0.3892, 0.8418, 0.6120,\n",
       "         0.4419, 0.5984, 0.1233, 0.2805, 0.3527, 0.4064, 0.0729],\n",
       "        [0.0541, 0.3726, 0.5885, 0.2594, 0.2256, 0.4928, 0.6285, 0.8817, 0.3214,\n",
       "         0.0804, 0.2417, 0.2847, 0.5816, 0.0747, 0.6608, 0.4212],\n",
       "        [0.8589, 0.9182, 0.7955, 0.6460, 0.5302, 0.9359, 0.3813, 0.8408, 0.3186,\n",
       "         0.5903, 0.0779, 0.4079, 0.4995, 0.8152, 0.2005, 0.7901],\n",
       "        [0.2897, 0.7436, 0.8832, 0.0783, 0.9728, 0.6027, 0.3496, 0.0415, 0.1770,\n",
       "         0.8253, 0.6632, 0.2593, 0.8494, 0.3972, 0.7324, 0.7599],\n",
       "        [0.1120, 0.3511, 0.2987, 0.9437, 0.6515, 0.6712, 0.9412, 0.3436, 0.1759,\n",
       "         0.0791, 0.5274, 0.3213, 0.8699, 0.8899, 0.3556, 0.2853],\n",
       "        [0.5677, 0.2861, 0.6666, 0.7117, 0.0619, 0.2136, 0.4949, 0.7089, 0.0188,\n",
       "         0.1645, 0.7114, 0.1970, 0.7854, 0.2025, 0.7806, 0.8581],\n",
       "        [0.7250, 0.5697, 0.0843, 0.3293, 0.2034, 0.0554, 0.0850, 0.1910, 0.9392,\n",
       "         0.7560, 0.6709, 0.1958, 0.2467, 0.0767, 0.5774, 0.3514],\n",
       "        [0.4852, 0.6873, 0.7841, 0.8713, 0.2902, 0.7676, 0.0334, 0.0519, 0.3088,\n",
       "         0.8429, 0.1501, 0.0591, 0.9100, 0.6772, 0.8635, 0.9863],\n",
       "        [0.3244, 0.3969, 0.2294, 0.4490, 0.8987, 0.6041, 0.6270, 0.5899, 0.3144,\n",
       "         0.3919, 0.3932, 0.0772, 0.2380, 0.7337, 0.0973, 0.5766],\n",
       "        [0.0657, 0.9317, 0.0740, 0.7669, 0.6412, 0.8705, 0.9636, 0.3183, 0.2818,\n",
       "         0.5409, 0.5247, 0.4422, 0.3752, 0.1893, 0.8434, 0.9252],\n",
       "        [0.6186, 0.8615, 0.4479, 0.6650, 0.5201, 0.3043, 0.7937, 0.8764, 0.4104,\n",
       "         0.8256, 0.8857, 0.9793, 0.8999, 0.9477, 0.0915, 0.1981]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "numerous-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1284, 0.4609, 0.6474, 0.1225, 0.7377, 0.7278, 0.6058, 0.1690, 0.9432,\n",
       "         0.1028, 0.1685, 0.1053, 0.1504, 0.7632, 0.9397, 0.9874],\n",
       "        [0.1142, 0.4097, 0.0415, 0.0466, 0.4397, 0.4605, 0.6003, 0.3397, 0.7229,\n",
       "         0.0350, 0.3080, 0.3023, 0.6102, 0.4022, 0.7245, 0.6958],\n",
       "        [0.8432, 0.9468, 0.5246, 0.0426, 0.2209, 0.9575, 0.4756, 0.2982, 0.8288,\n",
       "         0.4203, 0.2345, 0.0801, 0.6127, 0.2470, 0.2947, 0.7514],\n",
       "        [0.3764, 0.4112, 0.0183, 0.0548, 0.0918, 0.3340, 0.6501, 0.0254, 0.7362,\n",
       "         0.1834, 0.0801, 0.4031, 0.4761, 0.8685, 0.9882, 0.4145],\n",
       "        [0.7474, 0.2154, 0.7202, 0.3769, 0.0413, 0.0203, 0.8938, 0.5025, 0.4482,\n",
       "         0.7700, 0.7667, 0.3090, 0.0185, 0.0088, 0.6021, 0.1754],\n",
       "        [0.3486, 0.0917, 0.7565, 0.7979, 0.3406, 0.5527, 0.6249, 0.2442, 0.4527,\n",
       "         0.9543, 0.6371, 0.0965, 0.8205, 0.0014, 0.2247, 0.5695],\n",
       "        [0.4242, 0.5441, 0.8830, 0.0074, 0.8514, 0.8322, 0.9511, 0.3351, 0.2896,\n",
       "         0.6086, 0.1001, 0.6268, 0.4608, 0.2664, 0.1583, 0.9472]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "violent-paraguay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  4],\n",
       "         [11, 10],\n",
       "         [ 8,  1],\n",
       "         [10,  5],\n",
       "         [ 3,  8],\n",
       "         [ 4,  0],\n",
       "         [ 5,  7]],\n",
       "\n",
       "        [[ 1,  4],\n",
       "         [ 5,  6],\n",
       "         [ 8,  1],\n",
       "         [ 0,  9],\n",
       "         [10,  5],\n",
       "         [11,  0],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[ 0,  6],\n",
       "         [10,  1],\n",
       "         [ 7,  8],\n",
       "         [ 6,  4],\n",
       "         [ 1, 10],\n",
       "         [ 3,  9],\n",
       "         [ 8,  5]],\n",
       "\n",
       "        [[ 1,  8],\n",
       "         [ 5,  2],\n",
       "         [ 4,  9],\n",
       "         [ 3, 10],\n",
       "         [ 8,  5],\n",
       "         [11,  4],\n",
       "         [ 7,  7]],\n",
       "\n",
       "        [[ 7,  1],\n",
       "         [11,  6],\n",
       "         [ 3,  7],\n",
       "         [10,  9],\n",
       "         [ 6,  8],\n",
       "         [ 4,  5],\n",
       "         [ 8,  0]],\n",
       "\n",
       "        [[ 9,  4],\n",
       "         [10,  4],\n",
       "         [11,  4],\n",
       "         [ 0,  5],\n",
       "         [ 1,  5],\n",
       "         [ 2,  5],\n",
       "         [ 3,  5]],\n",
       "\n",
       "        [[ 0,  0],\n",
       "         [11,  3],\n",
       "         [ 2,  7],\n",
       "         [ 5, 10],\n",
       "         [ 9,  9],\n",
       "         [ 4,  6],\n",
       "         [ 3,  2]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [ 0,  0],\n",
       "         [ 3,  5],\n",
       "         [10,  4],\n",
       "         [ 6, 10],\n",
       "         [11,  2],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[10,  1],\n",
       "         [ 1,  4],\n",
       "         [11,  8],\n",
       "         [ 4,  0],\n",
       "         [ 3,  3],\n",
       "         [ 5,  5],\n",
       "         [ 7,  2]],\n",
       "\n",
       "        [[ 5,  0],\n",
       "         [ 1,  8],\n",
       "         [ 2, 10],\n",
       "         [ 3,  1],\n",
       "         [ 6,  7],\n",
       "         [11,  6],\n",
       "         [ 9,  3]],\n",
       "\n",
       "        [[10,  4],\n",
       "         [ 1,  3],\n",
       "         [11,  2],\n",
       "         [ 4,  1],\n",
       "         [ 9,  8],\n",
       "         [ 3,  7],\n",
       "         [ 8,  5]],\n",
       "\n",
       "        [[ 3,  4],\n",
       "         [ 7,  5],\n",
       "         [ 4,  8],\n",
       "         [ 1,  6],\n",
       "         [ 5,  0],\n",
       "         [ 6,  7],\n",
       "         [ 0,  3]],\n",
       "\n",
       "        [[ 7,  5],\n",
       "         [ 9,  3],\n",
       "         [10,  9],\n",
       "         [ 1,  8],\n",
       "         [ 5,  2],\n",
       "         [ 2, 10],\n",
       "         [ 4,  7]],\n",
       "\n",
       "        [[10,  5],\n",
       "         [ 2,  6],\n",
       "         [ 4, 10],\n",
       "         [ 9,  7],\n",
       "         [ 1,  2],\n",
       "         [ 7,  4],\n",
       "         [ 0,  1]],\n",
       "\n",
       "        [[ 4,  1],\n",
       "         [ 6,  0],\n",
       "         [ 2,  5],\n",
       "         [ 1,  9],\n",
       "         [ 8,  4],\n",
       "         [ 0, 10],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 2,  6],\n",
       "         [ 8,  6],\n",
       "         [ 1,  9],\n",
       "         [10,  9],\n",
       "         [11,  6],\n",
       "         [ 4,  9]]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "tender-nancy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1284, 0.4609, 0.6474, 0.1225, 0.7377, 0.7278, 0.6058, 0.1690, 0.9432,\n",
       "        0.1028, 0.1685, 0.1053, 0.1504, 0.7632, 0.9397, 0.9874])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "bored-following",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = torch.stack(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "joint-burst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1120, 0.3511, 0.2987,  ..., 0.8899, 0.3556, 0.2853],\n",
       "         [0.0671, 0.3123, 0.4280,  ..., 0.8033, 0.1922, 0.2846],\n",
       "         [0.8126, 0.4204, 0.9744,  ..., 0.0376, 0.3990, 0.2539],\n",
       "         ...,\n",
       "         [0.8382, 0.1435, 0.4875,  ..., 0.9609, 0.0997, 0.2042],\n",
       "         [0.4452, 0.7048, 0.0387,  ..., 0.2980, 0.6012, 0.6348],\n",
       "         [0.2810, 0.8880, 0.5160,  ..., 0.6879, 0.0503, 0.8594]],\n",
       "\n",
       "        [[0.0492, 0.4358, 0.4979,  ..., 0.7077, 0.5163, 0.7262],\n",
       "         [0.3250, 0.5925, 0.6502,  ..., 0.0340, 0.1978, 0.5048],\n",
       "         [0.8126, 0.4204, 0.9744,  ..., 0.0376, 0.3990, 0.2539],\n",
       "         ...,\n",
       "         [0.3723, 0.8729, 0.9098,  ..., 0.0397, 0.0191, 0.9223],\n",
       "         [0.3865, 0.7580, 0.3982,  ..., 0.5463, 0.5886, 0.2097],\n",
       "         [0.9739, 0.3567, 0.9348,  ..., 0.2981, 0.7180, 0.9402]],\n",
       "\n",
       "        [[0.1284, 0.4609, 0.6474,  ..., 0.7632, 0.9397, 0.9874],\n",
       "         [0.1142, 0.4097, 0.0415,  ..., 0.4022, 0.7245, 0.6958],\n",
       "         [0.8432, 0.9468, 0.5246,  ..., 0.2470, 0.2947, 0.7514],\n",
       "         ...,\n",
       "         [0.7474, 0.2154, 0.7202,  ..., 0.0088, 0.6021, 0.1754],\n",
       "         [0.3486, 0.0917, 0.7565,  ..., 0.0014, 0.2247, 0.5695],\n",
       "         [0.4242, 0.5441, 0.8830,  ..., 0.2664, 0.1583, 0.9472]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3723, 0.8729, 0.9098,  ..., 0.0397, 0.0191, 0.9223],\n",
       "         [0.7250, 0.5697, 0.0843,  ..., 0.0767, 0.5774, 0.3514],\n",
       "         [0.8951, 0.0581, 0.9894,  ..., 0.5149, 0.7740, 0.8711],\n",
       "         ...,\n",
       "         [0.9077, 0.5667, 0.3340,  ..., 0.9787, 0.7444, 0.5644],\n",
       "         [0.8132, 0.1108, 0.6408,  ..., 0.1020, 0.8876, 0.8708],\n",
       "         [0.3321, 0.3657, 0.2715,  ..., 0.0012, 0.1206, 0.8306]],\n",
       "\n",
       "        [[0.0438, 0.7872, 0.9399,  ..., 0.8502, 0.4640, 0.8329],\n",
       "         [0.7644, 0.7349, 0.5275,  ..., 0.0636, 0.8482, 0.1602],\n",
       "         [0.5677, 0.2861, 0.6666,  ..., 0.2025, 0.7806, 0.8581],\n",
       "         ...,\n",
       "         [0.8567, 0.5574, 0.6668,  ..., 0.1026, 0.8511, 0.1099],\n",
       "         [0.8036, 0.4993, 0.5126,  ..., 0.3757, 0.4247, 0.8041],\n",
       "         [0.9739, 0.3567, 0.9348,  ..., 0.2981, 0.7180, 0.9402]],\n",
       "\n",
       "        [[0.3250, 0.5925, 0.6502,  ..., 0.0340, 0.1978, 0.5048],\n",
       "         [0.7250, 0.5697, 0.0843,  ..., 0.0767, 0.5774, 0.3514],\n",
       "         [0.5013, 0.1117, 0.2290,  ..., 0.1751, 0.3436, 0.3594],\n",
       "         ...,\n",
       "         [0.6526, 0.8607, 0.5738,  ..., 0.6274, 0.5342, 0.3552],\n",
       "         [0.0502, 0.5997, 0.2017,  ..., 0.9276, 0.0028, 0.4839],\n",
       "         [0.4246, 0.2396, 0.6710,  ..., 0.1932, 0.0216, 0.6436]]])"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "incorporate-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = r.transpose(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "coated-backup",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9104, 0.3321, 0.1306,  ..., 0.6653, 0.6279, 0.8036],\n",
       "         [0.8869, 0.3657, 0.0304,  ..., 0.4979, 0.1830, 0.4993],\n",
       "         [0.6165, 0.2715, 0.8923,  ..., 0.6384, 0.1819, 0.5126],\n",
       "         ...,\n",
       "         [0.2963, 0.0012, 0.9134,  ..., 0.9108, 0.8808, 0.3757],\n",
       "         [0.0814, 0.1206, 0.6598,  ..., 0.7502, 0.9866, 0.4247],\n",
       "         [0.6967, 0.8306, 0.0088,  ..., 0.7491, 0.5935, 0.8041]],\n",
       "\n",
       "        [[0.2160, 0.3457, 0.9077,  ..., 0.9212, 0.5426, 0.7474],\n",
       "         [0.8171, 0.7326, 0.5667,  ..., 0.3648, 0.7438, 0.2154],\n",
       "         [0.5241, 0.8059, 0.3340,  ..., 0.0410, 0.5450, 0.7202],\n",
       "         ...,\n",
       "         [0.5238, 0.0643, 0.9787,  ..., 0.8499, 0.6198, 0.0088],\n",
       "         [0.7577, 0.6400, 0.7444,  ..., 0.6953, 0.2089, 0.6021],\n",
       "         [0.7468, 0.4580, 0.5644,  ..., 0.5501, 0.0760, 0.1754]],\n",
       "\n",
       "        [[0.4732, 0.0541, 0.8589,  ..., 0.3244, 0.0657, 0.6186],\n",
       "         [0.5070, 0.3726, 0.9182,  ..., 0.3969, 0.9317, 0.8615],\n",
       "         [0.9636, 0.5885, 0.7955,  ..., 0.2294, 0.0740, 0.4479],\n",
       "         ...,\n",
       "         [0.3527, 0.0747, 0.8152,  ..., 0.7337, 0.1893, 0.9477],\n",
       "         [0.4064, 0.6608, 0.2005,  ..., 0.0973, 0.8434, 0.0915],\n",
       "         [0.0729, 0.4212, 0.7901,  ..., 0.5766, 0.9252, 0.1981]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8640, 0.2474, 0.4760,  ..., 0.4446, 0.4904, 0.0204],\n",
       "         [0.5353, 0.7195, 0.3552,  ..., 0.2636, 0.8357, 0.5129],\n",
       "         [0.2196, 0.6607, 0.6873,  ..., 0.3981, 0.8945, 0.9323],\n",
       "         ...,\n",
       "         [0.7763, 0.9219, 0.1009,  ..., 0.0082, 0.7228, 0.5085],\n",
       "         [0.1191, 0.8822, 0.6673,  ..., 0.7349, 0.5101, 0.3749],\n",
       "         [0.8604, 0.5703, 0.6126,  ..., 0.8990, 0.8682, 0.1267]],\n",
       "\n",
       "        [[0.9685, 0.1142, 0.5163,  ..., 0.1450, 0.6526, 0.7560],\n",
       "         [0.3081, 0.4097, 0.4467,  ..., 0.9739, 0.8607, 0.6509],\n",
       "         [0.1808, 0.0415, 0.5030,  ..., 0.0774, 0.5738, 0.0236],\n",
       "         ...,\n",
       "         [0.8384, 0.4022, 0.9674,  ..., 0.2113, 0.6274, 0.6356],\n",
       "         [0.2183, 0.7245, 0.3289,  ..., 0.5174, 0.5342, 0.2552],\n",
       "         [0.0374, 0.6958, 0.7591,  ..., 0.1668, 0.3552, 0.6940]],\n",
       "\n",
       "        [[0.3865, 0.5561, 0.1239,  ..., 0.9296, 0.8557, 0.0671],\n",
       "         [0.7580, 0.5736, 0.0246,  ..., 0.3377, 0.4163, 0.3123],\n",
       "         [0.3982, 0.9257, 0.6756,  ..., 0.1197, 0.6815, 0.4280],\n",
       "         ...,\n",
       "         [0.5463, 0.5601, 0.3346,  ..., 0.6354, 0.8401, 0.8033],\n",
       "         [0.5886, 0.2272, 0.5506,  ..., 0.2692, 0.1971, 0.1922],\n",
       "         [0.2097, 0.1733, 0.2604,  ..., 0.6848, 0.2261, 0.2846]]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "dried-wilderness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.max(2).values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "inside-large",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9104, 0.3321, 0.1306, 0.1701, 0.0246, 0.2860, 0.1284, 0.9790, 0.6653,\n",
       "         0.6279, 0.8036],\n",
       "        [0.8869, 0.3657, 0.0304, 0.3983, 0.1003, 0.3791, 0.4609, 0.6941, 0.4979,\n",
       "         0.1830, 0.4993],\n",
       "        [0.6165, 0.2715, 0.8923, 0.9748, 0.0347, 0.0860, 0.6474, 0.8152, 0.6384,\n",
       "         0.1819, 0.5126],\n",
       "        [0.5080, 0.0428, 0.8240, 0.4820, 0.9513, 0.5244, 0.1225, 0.8729, 0.7272,\n",
       "         0.8866, 0.9049],\n",
       "        [0.8807, 0.8260, 0.1791, 0.1689, 0.6944, 0.1191, 0.7377, 0.9903, 0.5398,\n",
       "         0.0991, 0.3536],\n",
       "        [0.5095, 0.7136, 0.1346, 0.9863, 0.4646, 0.0387, 0.7278, 0.3336, 0.8501,\n",
       "         0.8577, 0.1676],\n",
       "        [0.5220, 0.3972, 0.2466, 0.6627, 0.2329, 0.1582, 0.6058, 0.8346, 0.5003,\n",
       "         0.5355, 0.6593],\n",
       "        [0.7413, 0.6915, 0.5133, 0.1083, 0.1208, 0.0350, 0.1690, 0.8238, 0.2513,\n",
       "         0.9098, 0.6602],\n",
       "        [0.7625, 0.0722, 0.0677, 0.8797, 0.5389, 0.5140, 0.9432, 0.4410, 0.8175,\n",
       "         0.9784, 0.2953],\n",
       "        [0.0304, 0.9568, 0.7030, 0.9898, 0.0111, 0.4151, 0.1028, 0.5120, 0.6824,\n",
       "         0.2545, 0.4735],\n",
       "        [0.9327, 0.9880, 0.2830, 0.3258, 0.7315, 0.6049, 0.1685, 0.5442, 0.2117,\n",
       "         0.7609, 0.0247],\n",
       "        [0.5717, 0.2851, 0.0752, 0.1710, 0.9235, 0.5907, 0.1053, 0.9895, 0.3534,\n",
       "         0.7669, 0.7469],\n",
       "        [0.6864, 0.4114, 0.1173, 0.0785, 0.5856, 0.0781, 0.1504, 0.0458, 0.7844,\n",
       "         0.8012, 0.0288],\n",
       "        [0.2963, 0.0012, 0.9134, 0.8341, 0.6418, 0.0634, 0.7632, 0.1771, 0.9108,\n",
       "         0.8808, 0.3757],\n",
       "        [0.0814, 0.1206, 0.6598, 0.2217, 0.6661, 0.2618, 0.9397, 0.5744, 0.7502,\n",
       "         0.9866, 0.4247],\n",
       "        [0.6967, 0.8306, 0.0088, 0.6363, 0.3209, 0.5034, 0.9874, 0.8925, 0.7491,\n",
       "         0.5935, 0.8041]])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "southern-front",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9790, 0.8869, 0.9748, 0.9513, 0.9903, 0.9863, 0.8346, 0.9098, 0.9784,\n",
       "        0.9898, 0.9880, 0.9895, 0.8012, 0.9134, 0.9866, 0.9874])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.max(2).values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "collect-borough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 7, 16])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "employed-perspective",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextq = r.max(2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "apart-stock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 16])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nextq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "quick-contact",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = torch.rand(12,16,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "voluntary-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_t = r.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "vocational-immune",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 11])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "digital-respect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12, 11])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_t[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "social-backup",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = r_t.max(2).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "fewer-sixth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 12])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "random-watts",
   "metadata": {},
   "outputs": [],
   "source": [
    "curQ = torch.rand(12,16,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "black-membrane",
   "metadata": {},
   "outputs": [],
   "source": [
    "nextQ = torch.rand(12,16,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "unknown-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "curQT = curQ.transpose(0,1)\n",
    "nextQT = nextQ.transpose(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "sunset-detail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2,  4],\n",
       "         [11, 10],\n",
       "         [ 8,  1],\n",
       "         [10,  5],\n",
       "         [ 3,  8],\n",
       "         [ 4,  0],\n",
       "         [ 5,  7]],\n",
       "\n",
       "        [[ 1,  4],\n",
       "         [ 5,  6],\n",
       "         [ 8,  1],\n",
       "         [ 0,  9],\n",
       "         [10,  5],\n",
       "         [11,  0],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[ 0,  6],\n",
       "         [10,  1],\n",
       "         [ 7,  8],\n",
       "         [ 6,  4],\n",
       "         [ 1, 10],\n",
       "         [ 3,  9],\n",
       "         [ 8,  5]],\n",
       "\n",
       "        [[ 1,  8],\n",
       "         [ 5,  2],\n",
       "         [ 4,  9],\n",
       "         [ 3, 10],\n",
       "         [ 8,  5],\n",
       "         [11,  4],\n",
       "         [ 7,  7]],\n",
       "\n",
       "        [[ 7,  1],\n",
       "         [11,  6],\n",
       "         [ 3,  7],\n",
       "         [10,  9],\n",
       "         [ 6,  8],\n",
       "         [ 4,  5],\n",
       "         [ 8,  0]],\n",
       "\n",
       "        [[ 9,  4],\n",
       "         [10,  4],\n",
       "         [11,  4],\n",
       "         [ 0,  5],\n",
       "         [ 1,  5],\n",
       "         [ 2,  5],\n",
       "         [ 3,  5]],\n",
       "\n",
       "        [[ 0,  0],\n",
       "         [11,  3],\n",
       "         [ 2,  7],\n",
       "         [ 5, 10],\n",
       "         [ 9,  9],\n",
       "         [ 4,  6],\n",
       "         [ 3,  2]],\n",
       "\n",
       "        [[ 8,  9],\n",
       "         [ 0,  0],\n",
       "         [ 3,  5],\n",
       "         [10,  4],\n",
       "         [ 6, 10],\n",
       "         [11,  2],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[10,  1],\n",
       "         [ 1,  4],\n",
       "         [11,  8],\n",
       "         [ 4,  0],\n",
       "         [ 3,  3],\n",
       "         [ 5,  5],\n",
       "         [ 7,  2]],\n",
       "\n",
       "        [[ 5,  0],\n",
       "         [ 1,  8],\n",
       "         [ 2, 10],\n",
       "         [ 3,  1],\n",
       "         [ 6,  7],\n",
       "         [11,  6],\n",
       "         [ 9,  3]],\n",
       "\n",
       "        [[10,  4],\n",
       "         [ 1,  3],\n",
       "         [11,  2],\n",
       "         [ 4,  1],\n",
       "         [ 9,  8],\n",
       "         [ 3,  7],\n",
       "         [ 8,  5]],\n",
       "\n",
       "        [[ 3,  4],\n",
       "         [ 7,  5],\n",
       "         [ 4,  8],\n",
       "         [ 1,  6],\n",
       "         [ 5,  0],\n",
       "         [ 6,  7],\n",
       "         [ 0,  3]],\n",
       "\n",
       "        [[ 7,  5],\n",
       "         [ 9,  3],\n",
       "         [10,  9],\n",
       "         [ 1,  8],\n",
       "         [ 5,  2],\n",
       "         [ 2, 10],\n",
       "         [ 4,  7]],\n",
       "\n",
       "        [[10,  5],\n",
       "         [ 2,  6],\n",
       "         [ 4, 10],\n",
       "         [ 9,  7],\n",
       "         [ 1,  2],\n",
       "         [ 7,  4],\n",
       "         [ 0,  1]],\n",
       "\n",
       "        [[ 4,  1],\n",
       "         [ 6,  0],\n",
       "         [ 2,  5],\n",
       "         [ 1,  9],\n",
       "         [ 8,  4],\n",
       "         [ 0, 10],\n",
       "         [ 7,  3]],\n",
       "\n",
       "        [[ 5,  6],\n",
       "         [ 2,  6],\n",
       "         [ 8,  6],\n",
       "         [ 1,  9],\n",
       "         [10,  9],\n",
       "         [11,  6],\n",
       "         [ 4,  9]]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "boolean-works",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4])\n",
      "tensor([11, 10])\n",
      "tensor([8, 1])\n",
      "tensor([10,  5])\n",
      "tensor([3, 8])\n",
      "tensor([4, 0])\n",
      "tensor([5, 7])\n",
      "0 [tensor(0.7771), tensor(0.5944), tensor(0.4784), tensor(0.7221), tensor(0.8025), tensor(0.3783), tensor(0.8618)]\n",
      "tensor([1, 4])\n",
      "tensor([5, 6])\n",
      "tensor([8, 1])\n",
      "tensor([0, 9])\n",
      "tensor([10,  5])\n",
      "tensor([11,  0])\n",
      "tensor([7, 3])\n",
      "1 [tensor(0.8534), tensor(0.9557), tensor(0.2724), tensor(0.2299), tensor(0.9522), tensor(0.4979), tensor(0.2348)]\n",
      "tensor([0, 6])\n",
      "tensor([10,  1])\n",
      "tensor([7, 8])\n",
      "tensor([6, 4])\n",
      "tensor([ 1, 10])\n",
      "tensor([3, 9])\n",
      "tensor([8, 5])\n",
      "2 [tensor(0.5527), tensor(0.3458), tensor(0.1226), tensor(0.6754), tensor(0.6724), tensor(0.6883), tensor(0.8497)]\n",
      "tensor([1, 8])\n",
      "tensor([5, 2])\n",
      "tensor([4, 9])\n",
      "tensor([ 3, 10])\n",
      "tensor([8, 5])\n",
      "tensor([11,  4])\n",
      "tensor([7, 7])\n",
      "3 [tensor(0.8964), tensor(0.8530), tensor(0.2013), tensor(0.3569), tensor(0.5445), tensor(0.3820), tensor(0.1739)]\n",
      "tensor([7, 1])\n",
      "tensor([11,  6])\n",
      "tensor([3, 7])\n",
      "tensor([10,  9])\n",
      "tensor([6, 8])\n",
      "tensor([4, 5])\n",
      "tensor([8, 0])\n",
      "4 [tensor(0.8632), tensor(0.4568), tensor(0.4727), tensor(0.3254), tensor(0.4041), tensor(0.2611), tensor(0.9774)]\n",
      "tensor([9, 4])\n",
      "tensor([10,  4])\n",
      "tensor([11,  4])\n",
      "tensor([0, 5])\n",
      "tensor([1, 5])\n",
      "tensor([2, 5])\n",
      "tensor([3, 5])\n",
      "5 [tensor(0.0572), tensor(0.9041), tensor(0.5388), tensor(0.7568), tensor(0.7201), tensor(0.1367), tensor(0.2211)]\n",
      "tensor([0, 0])\n",
      "tensor([11,  3])\n",
      "tensor([2, 7])\n",
      "tensor([ 5, 10])\n",
      "tensor([9, 9])\n",
      "tensor([4, 6])\n",
      "tensor([3, 2])\n",
      "6 [tensor(0.1683), tensor(0.8570), tensor(0.8176), tensor(0.1745), tensor(0.7391), tensor(0.2001), tensor(0.4361)]\n",
      "tensor([8, 9])\n",
      "tensor([0, 0])\n",
      "tensor([3, 5])\n",
      "tensor([10,  4])\n",
      "tensor([ 6, 10])\n",
      "tensor([11,  2])\n",
      "tensor([7, 3])\n",
      "7 [tensor(0.3796), tensor(0.7790), tensor(0.9209), tensor(0.2834), tensor(0.6400), tensor(0.0203), tensor(0.4039)]\n",
      "tensor([10,  1])\n",
      "tensor([1, 4])\n",
      "tensor([11,  8])\n",
      "tensor([4, 0])\n",
      "tensor([3, 3])\n",
      "tensor([5, 5])\n",
      "tensor([7, 2])\n",
      "8 [tensor(0.8423), tensor(0.0501), tensor(0.4075), tensor(0.2411), tensor(0.3802), tensor(0.2966), tensor(0.7632)]\n",
      "tensor([5, 0])\n",
      "tensor([1, 8])\n",
      "tensor([ 2, 10])\n",
      "tensor([3, 1])\n",
      "tensor([6, 7])\n",
      "tensor([11,  6])\n",
      "tensor([9, 3])\n",
      "9 [tensor(0.5256), tensor(0.3428), tensor(0.3927), tensor(0.3279), tensor(0.6852), tensor(0.5220), tensor(0.2146)]\n",
      "tensor([10,  4])\n",
      "tensor([1, 3])\n",
      "tensor([11,  2])\n",
      "tensor([4, 1])\n",
      "tensor([9, 8])\n",
      "tensor([3, 7])\n",
      "tensor([8, 5])\n",
      "10 [tensor(0.8384), tensor(0.1631), tensor(0.8600), tensor(0.0526), tensor(0.1630), tensor(0.2769), tensor(0.2912)]\n",
      "tensor([3, 4])\n",
      "tensor([7, 5])\n",
      "tensor([4, 8])\n",
      "tensor([1, 6])\n",
      "tensor([5, 0])\n",
      "tensor([6, 7])\n",
      "tensor([0, 3])\n",
      "11 [tensor(0.1068), tensor(0.9690), tensor(0.3571), tensor(0.7291), tensor(0.6605), tensor(0.0480), tensor(0.7991)]\n",
      "tensor([7, 5])\n",
      "tensor([9, 3])\n",
      "tensor([10,  9])\n",
      "tensor([1, 8])\n",
      "tensor([5, 2])\n",
      "tensor([ 2, 10])\n",
      "tensor([4, 7])\n",
      "12 [tensor(0.1034), tensor(0.7586), tensor(0.4068), tensor(0.7843), tensor(0.1543), tensor(0.4079), tensor(0.8442)]\n",
      "tensor([10,  5])\n",
      "tensor([2, 6])\n",
      "tensor([ 4, 10])\n",
      "tensor([9, 7])\n",
      "tensor([1, 2])\n",
      "tensor([7, 4])\n",
      "tensor([0, 1])\n",
      "13 [tensor(0.6098), tensor(0.3477), tensor(0.2809), tensor(0.9672), tensor(0.5778), tensor(0.1953), tensor(0.3480)]\n",
      "tensor([4, 1])\n",
      "tensor([6, 0])\n",
      "tensor([2, 5])\n",
      "tensor([1, 9])\n",
      "tensor([8, 4])\n",
      "tensor([ 0, 10])\n",
      "tensor([7, 3])\n",
      "14 [tensor(0.3034), tensor(0.7581), tensor(0.7727), tensor(0.5106), tensor(0.3758), tensor(0.6910), tensor(0.0617)]\n",
      "tensor([5, 6])\n",
      "tensor([2, 6])\n",
      "tensor([8, 6])\n",
      "tensor([1, 9])\n",
      "tensor([10,  9])\n",
      "tensor([11,  6])\n",
      "tensor([4, 9])\n",
      "15 [tensor(0.0898), tensor(0.7764), tensor(0.7943), tensor(0.1148), tensor(0.8183), tensor(0.7316), tensor(0.5223)]\n"
     ]
    }
   ],
   "source": [
    "for idx, group in enumerate(curQT):\n",
    "    new_curQT = []\n",
    "    for sub_act in a[idx]:\n",
    "        new_curQT.append(group[sub_act[0]][sub_act[1]])\n",
    "    print(idx, new_curQT)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-anthropology",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
