{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 660,
   "id": "stunning-glory",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from config import Configuration\n",
    "from noisy_net import NoisyLinear, NoisyFactorizedLinear\n",
    "from utils import state_pre_processing\n",
    "from OneHotEncode import OneHotEncode\n",
    "\n",
    "class BranchingQNetwork(nn.Module):\n",
    "    def __init__(self, observation_space, action_space, hidden_dim, exploration_method=\"Dueling\", architecture=\"DQN\"):\n",
    "        super().__init__()\n",
    "        self.architecture = architecture\n",
    "        self.model = nn.ModuleList([nn.Sequential(\n",
    "            nn.Linear(62, hidden_dim*4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*4, hidden_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim*2, hidden_dim),\n",
    "            nn.ReLU()\n",
    "        ) for i in range(12)])\n",
    "        if self.architecture == \"Dueling\":\n",
    "            self.value_head = nn.ModuleList([nn.Linear(hidden_dim, 1) for i in range(12)])\n",
    "            self.adv_heads = nn.ModuleList([nn.Linear(hidden_dim, 11) for i in range(12)])\n",
    "        else:\n",
    "            self.out = nn.ModuleList([nn.Linear(hidden_dim, 11) for i in range(12)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        processed_x = self.state_processing(x)\n",
    "        print(processed_x)\n",
    "        layer1 = torch.stack([self.model[i](processed_x[i]) for i, _ in enumerate(processed_x)])\n",
    "        if self.architecture == \"Dueling\":\n",
    "            value = torch.stack([self.value_head[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            advs = torch.stack([self.adv_heads[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            q_val = value + advs - advs.mean()\n",
    "        else:\n",
    "            q_val = torch.stack([self.out[i](layer1[i]) for i, _ in enumerate(layer1)])\n",
    "            \n",
    "        return q_val\n",
    "    \n",
    "    def state_processing(self, obs):\n",
    "        node_info = obs[:45]\n",
    "        groups_info = obs[45:]\n",
    "        partitions = [17 for i in range(12)]\n",
    "        groups = torch.split(groups_info, partitions)\n",
    "        groups_final = [torch.cat((node_info, groups[i])) for i in range(len(groups))]\n",
    "        return groups_final\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 661,
   "id": "wicked-couple",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x1c626dca190>"
      ]
     },
     "execution_count": 661,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Configuration(\"configs/config.json\")\n",
    "torch.cuda.init()\n",
    "device = torch.device(\n",
    "    config.device if torch.cuda.is_available() else \"cpu\")\n",
    "torch.autograd.set_detect_anomaly(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "id": "combined-twins",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = [  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,\n",
    "          0.,    0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,\n",
    "          0.,  -88.,    0.,    0.,    0., -100.,   16.,    0.,    0.,\n",
    "        100.,   12.,    0.,    1., -100.,   16.,    0.,    0.,  -50.,\n",
    "          7.,    1.,    0.,  -13.,    8.,    0.,    0., -500.,   32.,\n",
    "          3.,    1.,   94.,    1.,    8.,   10.,    2.,   56.,    1.,\n",
    "          7.,    8.,    0.,   93.,    0.,    8.,    6.,    1.,   58.,\n",
    "          0.,    8.,    8.,    2.,    0.,    0.,    0.,    4.,    0.,\n",
    "        100.,    0.,    8.,    7.,    1.,   90.,    0.,    8.,    2.,\n",
    "          2.,  100.,    0.,    8.,    7.,    0.,  100.,    0.,    8.,\n",
    "          2.,    1.,   15.,    0.,    7.,    9.,    2.,   70.,    0.,\n",
    "          8.,    2.,    0.,   91.,    1.,   12.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "id": "korean-mouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_obs = OneHotEncode(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "id": "eastern-denmark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
       "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
       "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
       "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
       "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    1.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,   94.,\n",
       "           1.,    8.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    1.,    0.,    0.,    1.,   56.,    1.,    7.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,\n",
       "           1.,    0.,    0.,   93.,    0.,    8.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
       "          58.,    0.,    8.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    1.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    1.,    0.,    0.,  100.,    0.,    8.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    1.,\n",
       "           0.,   90.,    0.,    8.,    0.,    0.,    1.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,  100.,    0.,\n",
       "           8.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
       "           0.,    0.,    1.,    0.,    0.,  100.,    0.,    8.,    0.,    0.,\n",
       "           1.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "           1.,    0.,   15.,    0.,    7.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    1.,   70.,\n",
       "           0.,    8.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    0.,\n",
       "           0.,    0.,    0.,    1.,    0.,    0.,   91.,    1.,   12.],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 664,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_obs = torch.tensor(new_obs).float().to(device)\n",
    "new_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-moment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "id": "adverse-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BranchingQNetwork(\n",
       "  (model): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (8): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (9): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (10): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "    (11): Sequential(\n",
       "      (0): Linear(in_features=62, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (out): ModuleList(\n",
       "    (0): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (2): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (3): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (4): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (5): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (6): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (7): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (8): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (9): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (10): Linear(in_features=128, out_features=11, bias=True)\n",
       "    (11): Linear(in_features=128, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 665,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BranchingQNetwork(249,11,128)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "id": "above-august",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    1.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,   94.,\n",
      "           1.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,    1.,   56.,\n",
      "           1.,    7.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    1.,    0.,    0.,    1.,    0.,    0.,   93.,\n",
      "           0.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    1.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,   58.,\n",
      "           0.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    1.,    0.,    0.,    0.,    0.,    1.,    0.,\n",
      "           0.,    0.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    1.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,  100.,\n",
      "           0.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    1.,    0.,    0.,    0.,    0.,    1.,    0.,   90.,\n",
      "           0.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    1.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,  100.,\n",
      "           0.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    1.,    0.,    0.,    0.,    1.,    0.,    0.,  100.,\n",
      "           0.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    1.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,   15.,\n",
      "           0.,    7.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    0.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    1.,    0.,    0.,    0.,    1.,   70.,\n",
      "           0.,    8.], device='cuda:0'), tensor([  64.,    0.,    0.,  500.,    0.,    0.,    1.,  100.,    8.,    0.,\n",
      "           0.,  100.,    0.,    1.,    0.,  100.,    0.,    0.,    0.,  -88.,\n",
      "           0.,    0.,    0., -100.,   16.,    0.,    0.,  100.,   12.,    0.,\n",
      "           1., -100.,   16.,    0.,    0.,  -50.,    7.,    1.,    0.,  -13.,\n",
      "           8.,    0.,    0., -500.,   32.,    0.,    0.,    1.,    0.,    0.,\n",
      "           0.,    0.,    0.,    0.,    0.,    0.,    1.,    0.,    0.,   91.,\n",
      "           1.,   12.], device='cuda:0')]\n",
      "tensor([[ -3.2565,  -4.7055,  -6.1925,   2.4195,   1.9261,  -0.6013,   1.1013,\n",
      "          -0.1916,   6.1156,  -4.0427,   1.0419],\n",
      "        [  2.5610,  -2.6171,   4.1217,  -4.4472,  -5.1828,  -2.1400,  -3.1551,\n",
      "           0.2058,   1.0037,  -2.1559,  -0.5176],\n",
      "        [  1.7436,  -4.8752,   1.5973,   1.7616,  -7.3911,   4.1566,  -0.4260,\n",
      "          -5.0502,   3.1783,   3.0542,  -4.3682],\n",
      "        [ -2.3171,  -8.4132,   3.9439,   3.4378,   2.1093,   8.2668,  -1.9333,\n",
      "           2.7334,  -0.5812,  -0.6860,  -5.5890],\n",
      "        [ -3.9553,   7.8626,  -0.0218,  -9.2002,  -3.7018,   1.4932,   2.1521,\n",
      "         -10.0563,  -6.0806,   0.1979,  -0.1013],\n",
      "        [ -1.2556,  -2.0960,   8.9283,  -0.8023,   6.9010,  -0.6223,   5.1500,\n",
      "          -2.3817,  -5.0319,  -1.2277,   3.8130],\n",
      "        [  0.1905,   0.2356,  -3.1500,   2.1712,   1.2822,   3.8871,  -0.8077,\n",
      "          -2.2372,   0.9844,   2.5816,  -4.5078],\n",
      "        [  6.7526,  -5.4479,  -7.3909,  -1.0373,  -3.8792,  -0.0353,   8.7734,\n",
      "           2.6215,   0.3894,  -1.7342,   5.5987],\n",
      "        [ -1.2268,   7.9842,  -2.4054,  -5.8487,  -1.7124,   4.3869,   2.3258,\n",
      "           0.6546,   0.8033,  -3.6440,   0.6619],\n",
      "        [ -1.2101,   4.2896,   2.6511,   5.9096,  -5.6240,  -3.5406,   0.5015,\n",
      "          -0.7416,  -1.0185,  -0.3337,  -2.0286],\n",
      "        [  5.4030,   4.4202,   9.0823,   2.3519,  -0.0863,   1.8578,   3.7839,\n",
      "          -1.8228,  -5.2208,   3.2468,  -0.0903],\n",
      "        [  4.2428,  -4.7135,   2.1545,   1.9332,  -1.1392,   4.3260,   1.8148,\n",
      "           6.6419,  -1.2855,   4.3257,  -4.1869]], device='cuda:0',\n",
      "       grad_fn=<StackBackward>)\n",
      "torch.return_types.max(\n",
      "values=tensor([6.1156, 4.1217, 4.1566, 8.2668, 7.8626, 8.9283, 3.8871, 8.7734, 7.9842,\n",
      "        5.9096, 9.0823, 6.6419], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([8, 2, 5, 5, 1, 2, 5, 6, 1, 3, 2, 7], device='cuda:0'))\n",
      "torch.return_types.sort(\n",
      "values=tensor([9.0823, 8.9283, 8.7734, 8.2668, 7.9842, 7.8626, 6.6419, 6.1156, 5.9096,\n",
      "        4.1566, 4.1217, 3.8871], device='cuda:0', grad_fn=<SortBackward>),\n",
      "indices=tensor([10,  5,  7,  3,  8,  4, 11,  0,  9,  2,  1,  6], device='cuda:0'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[10,  3],\n",
       "       [ 5,  3],\n",
       "       [ 7,  7],\n",
       "       [ 3,  6],\n",
       "       [ 8,  2],\n",
       "       [ 4,  2],\n",
       "       [11,  8]], dtype=int64)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(new_obs)\n",
    "print(out)\n",
    "out_max = out.max(1)\n",
    "print(out_max)\n",
    "out_max_sorted = out_max.values.sort(descending=True)\n",
    "print(out_max_sorted)\n",
    "chosen_group = out_max_sorted.indices[:7]\n",
    "chosen_location = torch.stack([out_max.indices[i] for i in chosen_group]) + 1\n",
    "action = torch.stack([chosen_group, chosen_location], dim = 1)\n",
    "action.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "id": "consolidated-comedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8, 2, 5, 5, 1, 2, 5, 6, 1, 3, 2, 7], device='cuda:0')"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(out,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "id": "involved-portuguese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[7.6681],\n",
       "        [4.3280],\n",
       "        [3.6627],\n",
       "        [3.3111],\n",
       "        [3.3614],\n",
       "        [6.7938],\n",
       "        [5.9988],\n",
       "        [7.9785],\n",
       "        [1.4474],\n",
       "        [3.6140],\n",
       "        [4.0060],\n",
       "        [4.4806]], device='cuda:0', grad_fn=<MaxBackward0>),\n",
       "indices=tensor([[ 4],\n",
       "        [ 8],\n",
       "        [10],\n",
       "        [ 3],\n",
       "        [ 7],\n",
       "        [ 2],\n",
       "        [ 4],\n",
       "        [ 2],\n",
       "        [ 9],\n",
       "        [ 0],\n",
       "        [ 0],\n",
       "        [ 2]], device='cuda:0'))"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = out.max(1, keepdim=True)\n",
    "q "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "greatest-heating",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 2] at entry 0 and [1] at entry 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-659-f47ec939c789>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [1, 2] at entry 0 and [1] at entry 1"
     ]
    }
   ],
   "source": [
    "g = torch.tensor([5])\n",
    "for i in range(5):\n",
    "    g = torch.stack((g,torch.tensor([5])),1)\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "id": "heard-smart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 1, 1])"
      ]
     },
     "execution_count": 842,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand(16)\n",
    "a = a.reshape(16,1,1)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "focal-basement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7653]],\n",
       "\n",
       "        [[0.8968]],\n",
       "\n",
       "        [[0.1491]],\n",
       "\n",
       "        [[0.5569]],\n",
       "\n",
       "        [[0.8454]],\n",
       "\n",
       "        [[0.4360]],\n",
       "\n",
       "        [[0.4331]],\n",
       "\n",
       "        [[0.7424]],\n",
       "\n",
       "        [[0.9555]],\n",
       "\n",
       "        [[0.2917]],\n",
       "\n",
       "        [[0.2802]],\n",
       "\n",
       "        [[0.6783]],\n",
       "\n",
       "        [[0.3563]],\n",
       "\n",
       "        [[0.4468]],\n",
       "\n",
       "        [[0.7109]],\n",
       "\n",
       "        [[0.7604]]])"
      ]
     },
     "execution_count": 843,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dirty-banking",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "id": "adverse-algeria",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1998, 0.5693, 0.4208, 0.8383, 0.5744, 0.5706, 0.3723, 0.5833,\n",
       "          0.7852, 0.2789, 0.1731]],\n",
       "\n",
       "        [[0.4356, 0.5773, 0.2484, 0.5187, 0.4292, 0.9952, 0.2208, 0.2657,\n",
       "          0.8074, 0.4296, 0.1393]],\n",
       "\n",
       "        [[0.2098, 0.0830, 0.8153, 0.7137, 0.1827, 0.0033, 0.0401, 0.6855,\n",
       "          0.0067, 0.5045, 0.0874]],\n",
       "\n",
       "        [[0.3700, 0.1646, 0.5977, 0.2931, 0.1988, 0.7953, 0.9809, 0.4848,\n",
       "          0.4476, 0.6978, 0.7244]],\n",
       "\n",
       "        [[0.0876, 0.1468, 0.3667, 0.8249, 0.3232, 0.0641, 0.0850, 0.4794,\n",
       "          0.7879, 0.5578, 0.1258]],\n",
       "\n",
       "        [[0.0020, 0.6110, 0.0785, 0.9579, 0.8489, 0.5749, 0.9852, 0.1104,\n",
       "          0.4834, 0.4429, 0.8309]],\n",
       "\n",
       "        [[0.4971, 0.1100, 0.4329, 0.3472, 0.5093, 0.8260, 0.9937, 0.5619,\n",
       "          0.5753, 0.2851, 0.7011]],\n",
       "\n",
       "        [[0.5411, 0.7743, 0.8090, 0.8835, 0.7705, 0.5820, 0.1611, 0.2945,\n",
       "          0.5745, 0.2372, 0.4310]],\n",
       "\n",
       "        [[0.1132, 0.9176, 0.7924, 0.5598, 0.9643, 0.6029, 0.2676, 0.3994,\n",
       "          0.9076, 0.3200, 0.2417]],\n",
       "\n",
       "        [[0.8257, 0.8166, 0.4680, 0.2396, 0.1601, 0.8872, 0.3967, 0.4103,\n",
       "          0.3430, 0.6026, 0.3016]],\n",
       "\n",
       "        [[0.3849, 0.4047, 0.9385, 0.8308, 0.8196, 0.5175, 0.4554, 0.4477,\n",
       "          0.6466, 0.2819, 0.9632]],\n",
       "\n",
       "        [[0.9755, 0.4560, 0.8331, 0.5776, 0.6018, 0.3984, 0.8564, 0.6020,\n",
       "          0.2848, 0.2120, 0.4258]],\n",
       "\n",
       "        [[0.1778, 0.6575, 0.9679, 0.9162, 0.8460, 0.9027, 0.0020, 0.5785,\n",
       "          0.4798, 0.8916, 0.1019]],\n",
       "\n",
       "        [[0.0114, 0.0868, 0.1788, 0.3452, 0.8515, 0.0419, 0.4890, 0.8497,\n",
       "          0.3222, 0.2288, 0.0587]],\n",
       "\n",
       "        [[0.9270, 0.6580, 0.2064, 0.2310, 0.8674, 0.8371, 0.1585, 0.0760,\n",
       "          0.7379, 0.5010, 0.5832]],\n",
       "\n",
       "        [[0.2078, 0.6042, 0.3034, 0.9257, 0.4483, 0.3716, 0.7218, 0.7732,\n",
       "          0.1600, 0.6615, 0.0946]]])"
      ]
     },
     "execution_count": 844,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.rand(16,1,11)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-carter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "id": "prepared-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9651, 1.3346, 1.1861, 1.6036, 1.3397, 1.3359, 1.1375, 1.3486,\n",
       "          1.5505, 1.0442, 0.9384]],\n",
       "\n",
       "        [[1.3324, 1.4741, 1.1452, 1.4155, 1.3259, 1.8920, 1.1175, 1.1625,\n",
       "          1.7041, 1.3264, 1.0360]],\n",
       "\n",
       "        [[0.3588, 0.2320, 0.9644, 0.8628, 0.3318, 0.1524, 0.1891, 0.8345,\n",
       "          0.1558, 0.6536, 0.2364]],\n",
       "\n",
       "        [[0.9269, 0.7215, 1.1545, 0.8500, 0.7557, 1.3522, 1.5378, 1.0417,\n",
       "          1.0044, 1.2546, 1.2813]],\n",
       "\n",
       "        [[0.9329, 0.9922, 1.2121, 1.6703, 1.1686, 0.9095, 0.9304, 1.3248,\n",
       "          1.6333, 1.4032, 0.9711]],\n",
       "\n",
       "        [[0.4381, 1.0471, 0.5145, 1.3939, 1.2849, 1.0109, 1.4212, 0.5464,\n",
       "          0.9194, 0.8789, 1.2669]],\n",
       "\n",
       "        [[0.9301, 0.5431, 0.8659, 0.7803, 0.9424, 1.2591, 1.4267, 0.9950,\n",
       "          1.0083, 0.7181, 1.1342]],\n",
       "\n",
       "        [[1.2835, 1.5167, 1.5514, 1.6259, 1.5128, 1.3244, 0.9035, 1.0369,\n",
       "          1.3169, 0.9796, 1.1733]],\n",
       "\n",
       "        [[1.0686, 1.8731, 1.7478, 1.5152, 1.9198, 1.5584, 1.2231, 1.3549,\n",
       "          1.8630, 1.2755, 1.1972]],\n",
       "\n",
       "        [[1.1174, 1.1083, 0.7597, 0.5313, 0.4519, 1.1790, 0.6884, 0.7020,\n",
       "          0.6348, 0.8944, 0.5934]],\n",
       "\n",
       "        [[0.6651, 0.6849, 1.2187, 1.1110, 1.0998, 0.7977, 0.7356, 0.7279,\n",
       "          0.9269, 0.5621, 1.2434]],\n",
       "\n",
       "        [[1.6537, 1.1343, 1.5113, 1.2559, 1.2801, 1.0766, 1.5346, 1.2802,\n",
       "          0.9631, 0.8903, 1.1041]],\n",
       "\n",
       "        [[0.5341, 1.0138, 1.3242, 1.2725, 1.2023, 1.2590, 0.3583, 0.9348,\n",
       "          0.8361, 1.2478, 0.4582]],\n",
       "\n",
       "        [[0.4582, 0.5336, 0.6256, 0.7920, 1.2983, 0.4887, 0.9358, 1.2966,\n",
       "          0.7690, 0.6756, 0.5055]],\n",
       "\n",
       "        [[1.6379, 1.3689, 0.9174, 0.9419, 1.5783, 1.5480, 0.8694, 0.7870,\n",
       "          1.4488, 1.2119, 1.2942]],\n",
       "\n",
       "        [[0.9682, 1.3647, 1.0638, 1.6862, 1.2087, 1.1321, 1.4822, 1.5337,\n",
       "          0.9204, 1.4219, 0.8550]]])"
      ]
     },
     "execution_count": 845,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 849,
   "id": "lucky-bachelor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([512, 62])\n",
      "torch.Size([512])\n",
      "torch.Size([256, 512])\n",
      "torch.Size([256])\n",
      "torch.Size([128, 256])\n",
      "torch.Size([128])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n",
      "torch.Size([11, 128])\n",
      "torch.Size([11])\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 850,
   "id": "considerable-candle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2847, 0.9113, 0.0964,  ..., 0.1876, 0.4767, 0.4001],\n",
       "         [0.1018, 0.7022, 0.9712,  ..., 0.7624, 0.3157, 0.5787],\n",
       "         [0.2565, 0.5069, 0.9032,  ..., 0.7857, 0.7244, 0.2263],\n",
       "         ...,\n",
       "         [0.6802, 0.4281, 0.1326,  ..., 0.0887, 0.3073, 0.8021],\n",
       "         [0.3660, 0.0319, 0.3379,  ..., 0.7866, 0.9094, 0.3821],\n",
       "         [0.5083, 0.8241, 0.8084,  ..., 0.0287, 0.8379, 0.8938]],\n",
       "\n",
       "        [[0.4168, 0.7862, 0.3454,  ..., 0.0983, 0.8514, 0.7829],\n",
       "         [0.3767, 0.4316, 0.2368,  ..., 0.3526, 0.8806, 0.5231],\n",
       "         [0.9336, 0.6520, 0.1217,  ..., 0.2220, 0.9908, 0.3037],\n",
       "         ...,\n",
       "         [0.7812, 0.5533, 0.1702,  ..., 0.4085, 0.2313, 0.0341],\n",
       "         [0.8024, 0.1569, 0.9195,  ..., 0.6120, 0.5205, 0.9044],\n",
       "         [0.9678, 0.4548, 0.7806,  ..., 0.4290, 0.3402, 0.7311]],\n",
       "\n",
       "        [[0.6870, 0.9280, 0.4295,  ..., 0.6931, 0.3435, 0.3322],\n",
       "         [0.8803, 0.5843, 0.6914,  ..., 0.1593, 0.0413, 0.3944],\n",
       "         [0.9179, 0.0275, 0.4062,  ..., 0.6539, 0.0363, 0.8127],\n",
       "         ...,\n",
       "         [0.3479, 0.2543, 0.3104,  ..., 0.1337, 0.5071, 0.6636],\n",
       "         [0.1093, 0.5739, 0.2310,  ..., 0.7732, 0.0437, 0.6108],\n",
       "         [0.3779, 0.5950, 0.8116,  ..., 0.4837, 0.7961, 0.4040]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.3197, 0.0242, 0.0236,  ..., 0.2529, 0.5022, 0.2994],\n",
       "         [0.5241, 0.5264, 0.5254,  ..., 0.7024, 0.4395, 0.8533],\n",
       "         [0.9712, 0.1422, 0.5568,  ..., 0.0817, 0.8615, 0.9105],\n",
       "         ...,\n",
       "         [0.8963, 0.7006, 0.6013,  ..., 0.4591, 0.3178, 0.7034],\n",
       "         [0.2239, 0.5041, 0.1193,  ..., 0.3964, 0.5110, 0.4154],\n",
       "         [0.8626, 0.2123, 0.0241,  ..., 0.3451, 0.4805, 0.2265]],\n",
       "\n",
       "        [[0.6722, 0.6731, 0.2677,  ..., 0.8874, 0.7761, 0.9353],\n",
       "         [0.5599, 0.7573, 0.7836,  ..., 0.6245, 0.6014, 0.1946],\n",
       "         [0.6440, 0.1213, 0.8752,  ..., 0.0106, 0.0149, 0.2158],\n",
       "         ...,\n",
       "         [0.0616, 0.3851, 0.6800,  ..., 0.7244, 0.7756, 0.8104],\n",
       "         [0.3897, 0.2221, 0.3204,  ..., 0.7795, 0.8199, 0.4446],\n",
       "         [0.9614, 0.3334, 0.3858,  ..., 0.6391, 0.7207, 0.2927]],\n",
       "\n",
       "        [[0.8189, 0.1252, 0.3205,  ..., 0.7920, 0.0026, 0.3255],\n",
       "         [0.0340, 0.1813, 0.2420,  ..., 0.2792, 0.7248, 0.4507],\n",
       "         [0.2685, 0.7467, 0.6285,  ..., 0.1716, 0.7269, 0.2797],\n",
       "         ...,\n",
       "         [0.1951, 0.5826, 0.3620,  ..., 0.9157, 0.2618, 0.5873],\n",
       "         [0.5410, 0.4156, 0.6263,  ..., 0.7184, 0.9565, 0.0448],\n",
       "         [0.2515, 0.6939, 0.5744,  ..., 0.7811, 0.5820, 0.4966]]])"
      ]
     },
     "execution_count": 850,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = torch.rand(16,12,62)\n",
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "operating-presentation",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-865-d834304e9a3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: stack(): argument 'tensors' (position 1) must be tuple of Tensors, not Tensor"
     ]
    }
   ],
   "source": [
    "torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aware-lightning",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
